import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.enum.text import PP_ALIGN, MSO_ANCHOR
from pptx.enum.shapes import MSO_SHAPE
import io
import tempfile
import os

# Set page config
st.set_page_config(page_title="Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°", layout="wide")

# Apply RTL (Right-to-Left) styling for Arabic
st.markdown("""
<style>
    /* Main container RTL */
    .main .block-container {
        direction: rtl;
        text-align: right;
    }
    
    /* Sidebar RTL */
    [data-testid="stSidebar"] {
        direction: rtl;
        text-align: right;
    }
    
    /* Headers and text */
    h1, h2, h3, h4, h5, h6, p, span, div, label {
        direction: rtl;
        text-align: right;
    }
    
    /* Metrics */
    [data-testid="stMetric"] {
        direction: rtl;
        text-align: center;
    }
    
    /* DataFrames */
    .stDataFrame {
        direction: rtl;
    }
    
    /* Tabs */
    .stTabs [data-baseweb="tab-list"] {
        direction: rtl;
        justify-content: flex-end;
    }
    
    /* Selectbox and inputs */
    .stSelectbox, .stMultiSelect, .stTextInput {
        direction: rtl;
    }
    
    /* Expander */
    .streamlit-expanderHeader {
        direction: rtl;
        text-align: right;
    }
    
    /* Info boxes */
    .stAlert {
        direction: rtl;
        text-align: right;
    }
    
    /* Download buttons */
    .stDownloadButton {
        direction: rtl;
    }
    
    /* Checkbox */
    .stCheckbox {
        direction: rtl;
    }
    
    /* Make columns flow RTL */
    [data-testid="column"] {
        direction: rtl;
    }
    
    /* File uploader */
    [data-testid="stFileUploader"] {
        direction: rtl;
    }
    
    /* Caption text */
    .stCaption {
        direction: rtl;
        text-align: right;
    }
    
    /* Markdown content */
    .stMarkdown {
        direction: rtl;
        text-align: right;
    }
    
    /* Tables inside dataframes - align text right */
    .dataframe th, .dataframe td {
        text-align: right !important;
    }
</style>
""", unsafe_allow_html=True)

# File uploader in sidebar
st.sidebar.header("ğŸ“ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù")
uploaded_file = st.sidebar.file_uploader(
    "Ø§Ø®ØªØ± Ù…Ù„Ù Excel",
    type=['xlsx', 'xls'],
    help="Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Excel ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°"
)

if uploaded_file is None:
    st.title("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°")
    st.markdown("---")
    st.info("ğŸ‘ˆ Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Excel Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡")
    st.markdown("""
    ### ğŸ“‹ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
    1. Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ **Browse files** ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
    2. Ø§Ø®ØªØ± Ù…Ù„Ù Excel ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°
    3. Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    4. Ø§Ø³ØªØ¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
    """)
    st.stop()

# Extract title from filename
app_title = Path(uploaded_file.name).stem.replace('_', ' - ')

# Title and intro
st.title(f"ğŸ“Š {app_title}")
st.markdown("---")

# Load data
@st.cache_data
def load_data(file_content, file_name):
    xls = pd.ExcelFile(io.BytesIO(file_content))
    sheet_names = xls.sheet_names
    
    # Filter out the first sheet if it's just a summary
    data_sheets = [s for s in sheet_names if s not in ['ExportMoGenNoteCcParMatie']]
    
    all_data = []
    for sheet in data_sheets:
        df = pd.read_excel(io.BytesIO(file_content), sheet_name=sheet, header=7)
        df['Ø§Ù„ÙØµÙ„'] = sheet  # Add class name
        all_data.append(df)
    
    return pd.concat(all_data, ignore_index=True)

# Load the data
file_content = uploaded_file.read()
df = load_data(file_content, uploaded_file.name)

# Convert grades from string (with commas) to float
subject_columns = [
    'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©',
    'Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ§Øª', 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª', 'Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­ÙŠØ§Ø© ÙˆØ§Ù„Ø£Ø±Ø¶',
    'Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ ÙˆØ§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡', 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©', 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¨Ø¯Ù†ÙŠØ©',
    'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…ÙŠØ§Øª', 'Ø§Ù„Ù…Ø¹Ø¯Ù„'
]

for col in subject_columns:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.'), errors='coerce')

# Sidebar for filtering
st.sidebar.markdown("---")
st.sidebar.header("ğŸ” Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµÙÙŠØ©")
if 'Ø§Ù„ÙØµÙ„' in df.columns:
    classes = ['Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØµÙˆÙ„'] + list(df['Ø§Ù„ÙØµÙ„'].unique())
    selected_class = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø§Ù„ÙØµÙ„:", classes)
    if selected_class == 'Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØµÙˆÙ„':
        df_filtered = df.copy()
    else:
        df_filtered = df[df['Ø§Ù„ÙØµÙ„'] == selected_class].copy()
else:
    df_filtered = df.copy()

# Remove rows with NaN in Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°
df_filtered = df_filtered.dropna(subset=['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°'])

# Overall Statistics
st.header("ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©")
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°", len(df_filtered))

with col2:
    avg_grade = df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean()
    st.metric("Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹Ø§Ù…", f"{avg_grade:.2f}")

with col3:
    max_grade = df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].max()
    st.metric("Ø£Ø¹Ù„Ù‰ Ù…Ø¹Ø¯Ù„", f"{max_grade:.2f}")

with col4:
    min_grade = df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].min()
    st.metric("Ø£Ø¯Ù†Ù‰ Ù…Ø¹Ø¯Ù„", f"{min_grade:.2f}")

st.markdown("---")

# Data Overview Table - Top & Bottom Performers
st.header("ğŸ† Ø£ÙØ¶Ù„ ÙˆØ£Ø¶Ø¹Ù Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°")

st.markdown("""
**Ù†Ø¸Ø±Ø© Ø³Ø±ÙŠØ¹Ø©:** Ø¬Ø¯ÙˆÙ„ ÙŠØ¹Ø±Ø¶ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…ØªÙÙˆÙ‚ÙŠÙ† ÙˆØ§Ù„Ù…ØªØ£Ø®Ø±ÙŠÙ† Ù…Ø¹ Ù†Ù‚Ø§Ø· Ù‚ÙˆØªÙ‡Ù… ÙˆØ¶Ø¹ÙÙ‡Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©.
""")

# Function to analyze student strengths and weaknesses
def analyze_student(row, subject_cols):
    scores = {}
    for col in subject_cols:
        if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in row.index and pd.notna(row.get(col)):
            scores[col] = row[col]
    
    if not scores:
        return "â€”", "â€”"
    
    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    # Best subject
    best_subj, best_score = sorted_scores[0]
    
    # Worst subject
    worst_subj, worst_score = sorted_scores[-1]
    
    # Generate strength description
    if best_score >= 18:
        strength = f"Ù…ØªÙ…ÙŠØ² ÙÙŠ {best_subj} ({best_score:.2f})"
    elif best_score >= 15:
        strength = f"Ù‚ÙˆÙŠ ÙÙŠ {best_subj} ({best_score:.2f})"
    else:
        strength = f"Ø£ÙØ¶Ù„ Ù…Ø§Ø¯Ø©: {best_subj} ({best_score:.2f})"
    
    # Check if struggling
    if worst_score < 10:
        strength += f" | ÙŠØ¹Ø§Ù†ÙŠ ÙÙŠ {worst_subj} ({worst_score:.2f})"
    
    return strength, worst_subj

# Get subject columns for analysis
analysis_subject_cols = [col for col in subject_columns if col in df_filtered.columns and col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„']

# Create top performers table
st.markdown("### ğŸ¥‡ Ø£ÙØ¶Ù„ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°")

top_students = df_filtered.nlargest(5, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')[['Ø±.Øª', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„'] + analysis_subject_cols].copy()
top_students = top_students.loc[:, ~top_students.columns.duplicated()]  # Remove duplicate columns
top_students['Ø§Ù„ØªØ±ØªÙŠØ¨'] = range(1, len(top_students) + 1)
top_students['Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©'] = top_students.apply(lambda row: analyze_student(row, analysis_subject_cols)[0], axis=1)

# Format rank
rank_labels = {1: 'ğŸ¥‡ Ø§Ù„Ø£ÙˆÙ„', 2: 'ğŸ¥ˆ Ø§Ù„Ø«Ø§Ù†ÙŠ', 3: 'ğŸ¥‰ Ø§Ù„Ø«Ø§Ù„Ø«', 4: '4ï¸âƒ£ Ø§Ù„Ø±Ø§Ø¨Ø¹', 5: '5ï¸âƒ£ Ø§Ù„Ø®Ø§Ù…Ø³'}
top_students['Ø§Ù„ØªØ±ØªÙŠØ¨'] = top_students['Ø§Ù„ØªØ±ØªÙŠØ¨'].map(rank_labels)

top_display = top_students[['Ø§Ù„ØªØ±ØªÙŠØ¨', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„', 'Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©']].copy()
top_display.loc[:, 'Ø§Ù„Ù…Ø¹Ø¯Ù„_formatted'] = top_display['Ø§Ù„Ù…Ø¹Ø¯Ù„'].astype(float).round(2).astype(str)
top_display = top_display[['Ø§Ù„ØªØ±ØªÙŠØ¨', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„_formatted', 'Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©']]
top_display.columns = ['Ø§Ù„ØªØ±ØªÙŠØ¨', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„', 'Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©']

st.dataframe(top_display, use_container_width=True, hide_index=True)

# Highlight top performer
if len(top_students) > 0:
    top_performer = df_filtered.loc[df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].idxmax()]
    top_subjects = {col: top_performer[col] for col in analysis_subject_cols if pd.notna(top_performer.get(col))}
    if top_subjects:
        perfect_subjects = [s for s, score in top_subjects.items() if score >= 18]
        if perfect_subjects:
            st.success(f"ğŸŒŸ **{top_performer['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']}** Ù…ØªÙ…ÙŠØ²(Ø©) Ø¨Ø´ÙƒÙ„ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ ÙÙŠ: {', '.join(perfect_subjects)}")

# Create bottom performers table
st.markdown("### ğŸ“‰ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø°ÙŠÙ† ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹")

bottom_students = df_filtered.nsmallest(5, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')[['Ø±.Øª', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„'] + analysis_subject_cols].copy()
bottom_students = bottom_students.loc[:, ~bottom_students.columns.duplicated()]  # Remove duplicate columns
bottom_students['Ø§Ù„ØªØ±ØªÙŠØ¨'] = range(len(df_filtered), len(df_filtered) - len(bottom_students), -1)

# Analyze weaknesses
def get_weakness_details(row, subject_cols):
    scores = {}
    for col in subject_cols:
        if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in row.index and pd.notna(row.get(col)):
            scores[col] = row[col]
    
    if not scores:
        return "â€”"
    
    sorted_scores = sorted(scores.items(), key=lambda x: x[1])
    failing_subjects = [(s, sc) for s, sc in sorted_scores if sc < 10]
    
    if failing_subjects:
        weakest = failing_subjects[0]
        if len(failing_subjects) > 1:
            return f"Ø¶Ø¹ÙŠÙ ÙÙŠ {weakest[0]} ({weakest[1]:.2f}) + {len(failing_subjects)-1} Ù…ÙˆØ§Ø¯ Ø£Ø®Ø±Ù‰"
        else:
            return f"ÙŠØ­ØªØ§Ø¬ Ø¯Ø¹Ù…Ø§Ù‹ ÙÙŠ {weakest[0]} ({weakest[1]:.2f})"
    else:
        best = sorted_scores[-1]
        return f"Ø£Ù‚ÙˆÙ‰ Ù…Ø§Ø¯Ø©: {best[0]} ({best[1]:.2f})"

bottom_students['Ø§Ù„ØªØ­Ù„ÙŠÙ„'] = bottom_students.apply(lambda row: get_weakness_details(row, analysis_subject_cols), axis=1)

# Find strength even for weak students
bottom_students['Ù†Ù‚Ø·Ø© Ù‚ÙˆØ©'] = bottom_students.apply(
    lambda row: max([(col, row[col]) for col in analysis_subject_cols if pd.notna(row.get(col))], 
                   key=lambda x: x[1], default=("â€”", 0))[0] if any(pd.notna(row.get(col)) for col in analysis_subject_cols) else "â€”",
    axis=1
)

bottom_display = bottom_students[['Ø§Ù„ØªØ±ØªÙŠØ¨', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„', 'Ù†Ù‚Ø·Ø© Ù‚ÙˆØ©', 'Ø§Ù„ØªØ­Ù„ÙŠÙ„']].copy()
bottom_display.loc[:, 'Ø§Ù„Ù…Ø¹Ø¯Ù„_formatted'] = bottom_display['Ø§Ù„Ù…Ø¹Ø¯Ù„'].astype(float).round(2).astype(str)
bottom_display = bottom_display[['Ø§Ù„ØªØ±ØªÙŠØ¨', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„_formatted', 'Ù†Ù‚Ø·Ø© Ù‚ÙˆØ©', 'Ø§Ù„ØªØ­Ù„ÙŠÙ„']]
bottom_display.columns = ['Ø§Ù„ØªØ±ØªÙŠØ¨', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„', 'Ù†Ù‚Ø·Ø© Ù‚ÙˆØ©', 'Ø§Ù„ØªØ­Ù„ÙŠÙ„']

st.dataframe(bottom_display, use_container_width=True, hide_index=True)

# Quick action recommendation
if len(bottom_students) > 0:
    worst_performer = df_filtered.loc[df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].idxmin()]
    worst_subjects = {col: worst_performer[col] for col in analysis_subject_cols if pd.notna(worst_performer.get(col)) and worst_performer[col] < 10}
    if worst_subjects:
        critical_subject = min(worst_subjects.items(), key=lambda x: x[1])
        st.warning(f"âš ï¸ **Ø¥Ø¬Ø±Ø§Ø¡ Ù…Ù‚ØªØ±Ø­:** Ø§Ù„ØªÙ„Ù…ÙŠØ°(Ø©) **{worst_performer['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']}** ÙŠØ­ØªØ§Ø¬ Ø¯Ø¹Ù…Ø§Ù‹ Ø¹Ø§Ø¬Ù„Ø§Ù‹ ÙÙŠ **{critical_subject[0]}** ({critical_subject[1]:.2f})")

# Borderline students (close to passing/failing)
st.markdown("### âš–ï¸ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ© (9-11)")

borderline = df_filtered[(df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 9) & (df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'] <= 11)].copy()
if len(borderline) > 0:
    borderline = borderline.sort_values('Ø§Ù„Ù…Ø¹Ø¯Ù„')[['Ø±.Øª', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„'] + analysis_subject_cols]
    borderline = borderline.loc[:, ~borderline.columns.duplicated()]  # Remove duplicate columns
    
    borderline['Ø§Ù„Ø­Ø§Ù„Ø©'] = borderline['Ø§Ù„Ù…Ø¹Ø¯Ù„'].apply(
        lambda x: 'ğŸ”´ Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„Ø±Ø³ÙˆØ¨' if float(x) < 10 else 'ğŸŸ¢ Ù†Ø§Ø¬Ø­ Ø¨ÙØ§Ø±Ù‚ Ø¨Ø³ÙŠØ·'
    )
    
    def get_weakest_subject(row):
        scores = [(col, row[col]) for col in analysis_subject_cols if col in row.index and pd.notna(row.get(col))]
        if scores:
            weakest = min(scores, key=lambda x: x[1])
            return f"{weakest[0]} ({float(weakest[1]):.2f})"
        return "â€”"
    
    borderline['Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø«Ø±Ø©'] = borderline.apply(get_weakest_subject, axis=1)
    
    borderline_display = borderline[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø«Ø±Ø©']].head(10).copy()
    borderline_display.loc[:, 'Ø§Ù„Ù…Ø¹Ø¯Ù„_formatted'] = borderline_display['Ø§Ù„Ù…Ø¹Ø¯Ù„'].astype(float).round(2).astype(str)
    borderline_display = borderline_display[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„_formatted', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø«Ø±Ø©']]
    borderline_display.columns = ['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„', 'Ø§Ù„Ø­Ø§Ù„Ø©', 'Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø«Ø±Ø©']
    
    st.dataframe(borderline_display, use_container_width=True, hide_index=True)
    
    # Quick insight
    below_10 = len(borderline[borderline['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 10])
    above_10 = len(borderline[borderline['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 10])
    st.info(f"ğŸ“Š Ù…Ù† Ø¨ÙŠÙ† {len(borderline)} ØªÙ„Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ©: **{below_10}** Ù‚Ø±ÙŠØ¨ÙˆÙ† Ù…Ù† Ø§Ù„Ø±Ø³ÙˆØ¨ØŒ **{above_10}** Ù†Ø§Ø¬Ø­ÙˆÙ† Ø¨ÙØ§Ø±Ù‚ Ø¨Ø³ÙŠØ·")
else:
    st.success("âœ… Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø­Ø§ÙØ© Ø§Ù„Ù†Ø¬Ø§Ø­/Ø§Ù„Ø±Ø³ÙˆØ¨")

st.markdown("---")

# Grade Brackets Analysis
st.header("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª")

# Create grade brackets
def get_bracket(grade):
    if pd.isna(grade):
        return None
    elif grade < 10:
        return "0 - 9.99 (Ø¯ÙˆÙ† Ø§Ù„Ù…Ø¹Ø¯Ù„)"
    elif grade < 12:
        return "10 - 11.99 (Ù…ØªÙˆØ³Ø·)"
    else:
        return "12 - 20 (Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø²)"

df_filtered['Bracket'] = df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].apply(get_bracket)

# Calculate bracket statistics
bracket_stats = df_filtered.groupby('Bracket').agg({
    'Ø§Ù„Ù…Ø¹Ø¯Ù„': ['count', 'mean', 'min', 'max', 'std']
}).round(2)
bracket_stats.columns = ['Count', 'Mean', 'Min', 'Max', 'Std Dev']
bracket_stats = bracket_stats.reset_index()

# Display metrics for each bracket
col1, col2, col3 = st.columns(3)

below_avg = df_filtered[df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 10]
average = df_filtered[(df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 10) & (df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 12)]
good = df_filtered[df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 12]

with col1:
    st.markdown("### ğŸ”´ Ø¯ÙˆÙ† Ø§Ù„Ù…Ø¹Ø¯Ù„ (0 - 9.99)")
    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°", len(below_avg))
    if len(below_avg) > 0:
        st.metric("Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©", f"{len(below_avg)/len(df_filtered)*100:.1f}%")
        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø¯Ù„", f"{below_avg['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean():.2f}")

with col2:
    st.markdown("### ğŸŸ¡ Ù…ØªÙˆØ³Ø· (10 - 11.99)")
    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°", len(average))
    if len(average) > 0:
        st.metric("Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©", f"{len(average)/len(df_filtered)*100:.1f}%")
        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø¯Ù„", f"{average['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean():.2f}")

with col3:
    st.markdown("### ğŸŸ¢ Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø² (12 - 20)")
    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°", len(good))
    if len(good) > 0:
        st.metric("Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ©", f"{len(good)/len(df_filtered)*100:.1f}%")
        st.metric("Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø¯Ù„", f"{good['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean():.2f}")

# Pie chart for bracket distribution
st.subheader("ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±Ø§Ø¦Ø­")
bracket_counts = df_filtered['Bracket'].value_counts().reset_index()
bracket_counts.columns = ['Bracket', 'Count']

col1, col2 = st.columns(2)

with col1:
    fig = px.pie(
        bracket_counts,
        values='Count',
        names='Bracket',
        color='Bracket',
        color_discrete_map={
            "0 - 9.99 (Ø¯ÙˆÙ† Ø§Ù„Ù…Ø¹Ø¯Ù„)": "#EF553B",
            "10 - 11.99 (Ù…ØªÙˆØ³Ø·)": "#FECB52",
            "12 - 20 (Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø²)": "#00CC96"
        }
    )
    fig.update_traces(textposition='inside', textinfo='percent+value')
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

with col2:
    # Insights summary
    st.markdown("### ğŸ’¡ Ø£Ù‡Ù… Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª")
    total = len(df_filtered)
    
    # Success rate (>=10)
    success_rate = (len(average) + len(good)) / total * 100 if total > 0 else 0
    st.info(f"**Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ (â‰¥10):** {success_rate:.1f}% Ù…Ù† Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ù†Ø§Ø¬Ø­ÙˆÙ†")
    
    # Excellence rate (>=12)
    excellence_rate = len(good) / total * 100 if total > 0 else 0
    st.success(f"**Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ…ÙŠØ² (â‰¥12):** {excellence_rate:.1f}% Ø­ØµÙ„ÙˆØ§ Ø¹Ù„Ù‰ Ù…Ø¹Ø¯Ù„ Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø²")
    
    # At-risk students
    at_risk_rate = len(below_avg) / total * 100 if total > 0 else 0
    if at_risk_rate > 0:
        st.warning(f"**ØªÙ„Ø§Ù…ÙŠØ° ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹ (<10):** {at_risk_rate:.1f}% ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ù…ØªØ§Ø¨Ø¹Ø© Ø¥Ø¶Ø§ÙÙŠØ©")
    
    # Performance summary
    if success_rate >= 80:
        st.markdown("âœ… **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…:** Ù…Ù…ØªØ§Ø² - Ù…Ø¹Ø¸Ù… Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ù†Ø§Ø¬Ø­ÙˆÙ†")
    elif success_rate >= 60:
        st.markdown("âš ï¸ **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…:** Ø¬ÙŠØ¯ - Ø§Ù„Ø£ØºÙ„Ø¨ÙŠØ© Ù†Ø§Ø¬Ø­ÙˆÙ† Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªØ­Ø³Ù†")
    else:
        st.markdown("ğŸš¨ **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…:** ÙŠØ­ØªØ§Ø¬ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Ù‹ - ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠÙˆØ§Ø¬Ù‡ÙˆÙ† ØµØ¹ÙˆØ¨Ø§Øª")

# Students list by bracket
st.subheader("ğŸ“‹ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±ÙŠØ­Ø©")
bracket_tab1, bracket_tab2, bracket_tab3 = st.tabs(["ğŸ”´ Ø¯ÙˆÙ† Ø§Ù„Ù…Ø¹Ø¯Ù„", "ğŸŸ¡ Ù…ØªÙˆØ³Ø·", "ğŸŸ¢ Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø²"])

with bracket_tab1:
    if len(below_avg) > 0:
        st.dataframe(below_avg[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„ÙØµÙ„', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']].sort_values('Ø§Ù„Ù…Ø¹Ø¯Ù„', ascending=False), use_container_width=True)
    else:
        st.success("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø´Ø±ÙŠØ­Ø©!")

with bracket_tab2:
    if len(average) > 0:
        st.dataframe(average[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„ÙØµÙ„', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']].sort_values('Ø§Ù„Ù…Ø¹Ø¯Ù„', ascending=False), use_container_width=True)
    else:
        st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø´Ø±ÙŠØ­Ø©")

with bracket_tab3:
    if len(good) > 0:
        st.dataframe(good[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„ÙØµÙ„', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']].sort_values('Ø§Ù„Ù…Ø¹Ø¯Ù„', ascending=False), use_container_width=True)
    else:
        st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø´Ø±ÙŠØ­Ø©")

st.markdown("---")

# Detailed Statistics by Subject
st.header("ğŸ“š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©")

# Calculate statistics for each subject
stats_data = []
for col in subject_columns:
    if col in df_filtered.columns:
        valid_data = df_filtered[col].dropna()
        if len(valid_data) > 0:
            stats_data.append({
                'Ø§Ù„Ù…Ø§Ø¯Ø©': col,
                'Ø§Ù„Ù…ØªÙˆØ³Ø·': valid_data.mean(),
                'Ø§Ù„Ø£Ø¹Ù„Ù‰': valid_data.max(),
                'Ø§Ù„Ø£Ù‚Ù„': valid_data.min(),
                'Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ': valid_data.std(),
                'Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨': len(valid_data)
            })

stats_df = pd.DataFrame(stats_data)

# Display table
st.dataframe(
    stats_df.style.format({
        'Ø§Ù„Ù…ØªÙˆØ³Ø·': '{:.2f}',
        'Ø§Ù„Ø£Ø¹Ù„Ù‰': '{:.2f}',
        'Ø§Ù„Ø£Ù‚Ù„': '{:.2f}',
        'Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ': '{:.2f}'
    }),
    use_container_width=True
)

st.markdown("---")

# Visualizations
st.header("ğŸ“Š Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©")

col1, col2 = st.columns(2)

# Average grades by subject
with col1:
    st.subheader("Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©")
    fig = px.bar(
        stats_df.sort_values('Ø§Ù„Ù…ØªÙˆØ³Ø·', ascending=True),
        x='Ø§Ù„Ù…ØªÙˆØ³Ø·',
        y='Ø§Ù„Ù…Ø§Ø¯Ø©',
        orientation='h',
        color='Ø§Ù„Ù…ØªÙˆØ³Ø·',
        color_continuous_scale='Viridis'
    )
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

# Grade distribution
with col2:
    st.subheader("ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª")
    fig = px.histogram(
        df_filtered,
        x='Ø§Ù„Ù…Ø¹Ø¯Ù„',
        nbins=20,
        color_discrete_sequence=['#636EFA']
    )
    fig.add_vline(df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean(), line_dash="dash", line_color="red", 
                   annotation_text=f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean():.2f}")
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

st.markdown("---")

# Student Rankings
st.header("ğŸ† Ø£ÙØ¶Ù„ 10 ØªÙ„Ø§Ù…ÙŠØ° Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¹Ø¯Ù„")
top_students = df_filtered[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']].dropna().nlargest(10, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')
st.dataframe(top_students.reset_index(drop=True), use_container_width=True)

st.markdown("---")

# Performance by Subject - Box Plot
st.header("ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©")

st.markdown("""
**ğŸ“– ÙƒÙŠÙÙŠØ© Ù‚Ø±Ø§Ø¡Ø© Ù‡Ø°Ø§ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ:**
- **Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚** ÙŠÙˆØ¶Ø­ Ø£ÙŠÙ† ØªÙ‚Ø¹ Ù…Ø¹Ø¸Ù… Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° (50% Ø§Ù„ÙˆØ³Ø·Ù‰)
- **Ø§Ù„Ø®Ø· Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚** Ù‡Ùˆ Ø§Ù„ÙˆØ³ÙŠØ· (Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø£ÙˆØ³Ø·)
- **Ø§Ù„Ø´Ø¹ÙŠØ±Ø§Øª** (Ø§Ù„Ø®Ø·ÙˆØ· Ø§Ù„Ù…Ù…ØªØ¯Ø© Ù…Ù† Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚) ØªÙˆØ¶Ø­ Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ©
- **Ø§Ù„Ù†Ù‚Ø§Ø· Ø®Ø§Ø±Ø¬** Ø§Ù„Ø´Ø¹ÙŠØ±Ø§Øª Ù‡ÙŠ Ù‚ÙŠÙ… Ø´Ø§Ø°Ø© (Ù…Ø¹Ø¯Ù„Ø§Øª Ù…Ø±ØªÙØ¹Ø© Ø£Ùˆ Ù…Ù†Ø®ÙØ¶Ø© Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ø¹Ø§Ø¯ÙŠ)
- **ØµÙ†Ø¯ÙˆÙ‚ Ø£Ø·ÙˆÙ„** ÙŠØ¹Ù†ÙŠ ØªØ¨Ø§ÙŠÙ† Ø£ÙƒØ¨Ø± ÙÙŠ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ù„ØªÙ„Ùƒ Ø§Ù„Ù…Ø§Ø¯Ø©
- **ØµÙ†Ø¯ÙˆÙ‚ ÙÙŠ Ù…ÙˆØ¶Ø¹ Ø£Ø¹Ù„Ù‰** ÙŠØ¹Ù†ÙŠ Ø£Ø¯Ø§Ø¡ Ø¹Ø§Ù… Ø£ÙØ¶Ù„ ÙÙŠ ØªÙ„Ùƒ Ø§Ù„Ù…Ø§Ø¯Ø©
""")

subject_data = []
for col in subject_columns:
    if col in df_filtered.columns:
        valid_data = df_filtered[col].dropna()
        for grade in valid_data:
            subject_data.append({'Ø§Ù„Ù…Ø§Ø¯Ø©': col, 'Ø§Ù„ØªÙ‚Ø¯ÙŠØ±': grade})

if subject_data:
    subject_box_df = pd.DataFrame(subject_data)
    fig = px.box(subject_box_df, x='Ø§Ù„Ù…Ø§Ø¯Ø©', y='Ø§Ù„ØªÙ‚Ø¯ÙŠØ±', color='Ø§Ù„Ù…Ø§Ø¯Ø©')
    fig.update_layout(height=500, showlegend=False)
    st.plotly_chart(fig, use_container_width=True)
    
    # Add subject-specific insights
    st.markdown("### ğŸ“ˆ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø­ÙˆÙ„ Ø§Ù„Ù…ÙˆØ§Ø¯")
    col1, col2 = st.columns(2)
    
    with col1:
        # Best performing subject
        best_subject = stats_df.loc[stats_df['Ø§Ù„Ù…ØªÙˆØ³Ø·'].idxmax()]
        st.success(f"**Ø£ÙØ¶Ù„ Ù…Ø§Ø¯Ø© Ø£Ø¯Ø§Ø¡Ù‹:** {best_subject['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ù…ØªÙˆØ³Ø·: {best_subject['Ø§Ù„Ù…ØªÙˆØ³Ø·']:.2f})")
        
        # Most consistent subject (lowest std dev)
        most_consistent = stats_df.loc[stats_df['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ'].idxmin()]
        st.info(f"**Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹:** {most_consistent['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {most_consistent['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ']:.2f})")
    
    with col2:
        # Subject needing attention
        worst_subject = stats_df.loc[stats_df['Ø§Ù„Ù…ØªÙˆØ³Ø·'].idxmin()]
        st.warning(f"**ØªØ­ØªØ§Ø¬ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Ù‹:** {worst_subject['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ù…ØªÙˆØ³Ø·: {worst_subject['Ø§Ù„Ù…ØªÙˆØ³Ø·']:.2f})")
        
        # Most varied subject (highest std dev)
        most_varied = stats_df.loc[stats_df['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ'].idxmax()]
        st.info(f"**Ø§Ù„Ø£ÙƒØ«Ø± ØªØ¨Ø§ÙŠÙ†Ø§Ù‹:** {most_varied['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {most_varied['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ']:.2f})")

st.markdown("---")

# Science vs Humanities Analysis
st.header("ğŸ”¬ğŸ“š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„Ø¢Ø¯Ø§Ø¨")

st.markdown("""
**ØªØ­Ù„ÙŠÙ„ ØªÙˆØ¬Ù‡ Ø§Ù„ÙØµÙ„:** Ù‡Ù„ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø£Ù… Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©ØŸ
""")

# Define subject groups
science_subjects = ['Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª', 'Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­ÙŠØ§Ø© ÙˆØ§Ù„Ø£Ø±Ø¶', 'Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ ÙˆØ§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡']
humanities_subjects = ['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©', 'Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ§Øª']

# Calculate averages for each group
science_scores = []
humanities_scores = []

for col in science_subjects:
    if col in df_filtered.columns:
        valid_data = df_filtered[col].dropna()
        science_scores.extend(valid_data.tolist())

for col in humanities_subjects:
    if col in df_filtered.columns:
        valid_data = df_filtered[col].dropna()
        humanities_scores.extend(valid_data.tolist())

science_avg = np.mean(science_scores) if science_scores else 0
humanities_avg = np.mean(humanities_scores) if humanities_scores else 0

# Per-student comparison
student_science_avg = []
student_humanities_avg = []

for idx, row in df_filtered.iterrows():
    sci_vals = [row[col] for col in science_subjects if col in df_filtered.columns and pd.notna(row.get(col))]
    hum_vals = [row[col] for col in humanities_subjects if col in df_filtered.columns and pd.notna(row.get(col))]
    
    if sci_vals:
        student_science_avg.append(np.mean(sci_vals))
    if hum_vals:
        student_humanities_avg.append(np.mean(hum_vals))

# Display comparison
col1, col2, col3 = st.columns(3)

with col1:
    st.markdown("### ğŸ”¬ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©")
    st.metric("Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø§Ù…", f"{science_avg:.2f}")
    st.caption(f"Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§ØªØŒ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­ÙŠØ§Ø© ÙˆØ§Ù„Ø£Ø±Ø¶ØŒ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ ÙˆØ§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡")

with col2:
    st.markdown("### ğŸ“š Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©")
    st.metric("Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø§Ù…", f"{humanities_avg:.2f}")
    st.caption(f"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©ØŒ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ§Øª")

with col3:
    st.markdown("### ğŸ“Š Ø§Ù„ÙØ±Ù‚")
    diff = science_avg - humanities_avg
    if diff > 0:
        st.metric("Ø§Ù„ØªÙˆØ¬Ù‡", f"Ø¹Ù„Ù…ÙŠ (+{diff:.2f})", delta=f"+{diff:.2f}")
    elif diff < 0:
        st.metric("Ø§Ù„ØªÙˆØ¬Ù‡", f"Ø£Ø¯Ø¨ÙŠ ({diff:.2f})", delta=f"{diff:.2f}")
    else:
        st.metric("Ø§Ù„ØªÙˆØ¬Ù‡", "Ù…ØªÙˆØ§Ø²Ù†", delta="0.00")

# Visualization
col1, col2 = st.columns(2)

with col1:
    # Bar chart comparison
    comparison_df = pd.DataFrame({
        'Ø§Ù„Ù…Ø¬Ø§Ù„': ['Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ© ğŸ”¬', 'Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© ğŸ“š'],
        'Ø§Ù„Ù…ØªÙˆØ³Ø·': [science_avg, humanities_avg]
    })
    
    fig = px.bar(
        comparison_df,
        x='Ø§Ù„Ù…Ø¬Ø§Ù„',
        y='Ø§Ù„Ù…ØªÙˆØ³Ø·',
        color='Ø§Ù„Ù…Ø¬Ø§Ù„',
        color_discrete_map={
            'Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ© ğŸ”¬': '#636EFA',
            'Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ© ğŸ“š': '#EF553B'
        },
        text='Ø§Ù„Ù…ØªÙˆØ³Ø·'
    )
    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')
    fig.update_layout(height=400, showlegend=False)
    fig.add_hline(y=10, line_dash="dash", line_color="green", annotation_text="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ (10)")
    st.plotly_chart(fig, use_container_width=True)

with col2:
    # Detailed subject comparison
    subject_comparison = []
    for col in science_subjects:
        if col in df_filtered.columns:
            avg = df_filtered[col].dropna().mean()
            subject_comparison.append({'Ø§Ù„Ù…Ø§Ø¯Ø©': col, 'Ø§Ù„Ù…ØªÙˆØ³Ø·': avg, 'Ø§Ù„Ù…Ø¬Ø§Ù„': 'Ø¹Ù„Ù…ÙŠ'})
    
    for col in humanities_subjects:
        if col in df_filtered.columns:
            avg = df_filtered[col].dropna().mean()
            subject_comparison.append({'Ø§Ù„Ù…Ø§Ø¯Ø©': col, 'Ø§Ù„Ù…ØªÙˆØ³Ø·': avg, 'Ø§Ù„Ù…Ø¬Ø§Ù„': 'Ø£Ø¯Ø¨ÙŠ'})
    
    if subject_comparison:
        subject_comp_df = pd.DataFrame(subject_comparison)
        fig = px.bar(
            subject_comp_df.sort_values('Ø§Ù„Ù…ØªÙˆØ³Ø·', ascending=True),
            x='Ø§Ù„Ù…ØªÙˆØ³Ø·',
            y='Ø§Ù„Ù…Ø§Ø¯Ø©',
            color='Ø§Ù„Ù…Ø¬Ø§Ù„',
            orientation='h',
            color_discrete_map={'Ø¹Ù„Ù…ÙŠ': '#636EFA', 'Ø£Ø¯Ø¨ÙŠ': '#EF553B'}
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)

# Insights
st.markdown("### ğŸ’¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ¬Ù‡")

if abs(diff) < 0.5:
    st.success("âœ… **Ø§Ù„ÙØµÙ„ Ù…ØªÙˆØ§Ø²Ù†:** Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…ØªÙ‚Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ© ÙˆØ§Ù„Ø£Ø¯Ø¨ÙŠØ©.")
elif diff >= 2:
    st.info("ğŸ”¬ **ØªÙˆØ¬Ù‡ Ø¹Ù„Ù…ÙŠ Ù‚ÙˆÙŠ:** Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠØªÙÙˆÙ‚ÙˆÙ† Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©.")
elif diff >= 0.5:
    st.info("ğŸ”¬ **ØªÙˆØ¬Ù‡ Ø¹Ù„Ù…ÙŠ Ø·ÙÙŠÙ:** Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©.")
elif diff <= -2:
    st.info("ğŸ“š **ØªÙˆØ¬Ù‡ Ø£Ø¯Ø¨ÙŠ Ù‚ÙˆÙŠ:** Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠØªÙÙˆÙ‚ÙˆÙ† Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©.")
else:
    st.info("ğŸ“š **ØªÙˆØ¬Ù‡ Ø£Ø¯Ø¨ÙŠ Ø·ÙÙŠÙ:** Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©.")

# Student distribution by tilt
if student_science_avg and student_humanities_avg and len(student_science_avg) == len(student_humanities_avg):
    df_filtered_copy = df_filtered.copy()
    df_filtered_copy['Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø¹Ù„ÙˆÙ…'] = student_science_avg[:len(df_filtered)]
    df_filtered_copy['Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø¢Ø¯Ø§Ø¨'] = student_humanities_avg[:len(df_filtered)]
    df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] = df_filtered_copy['Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø¹Ù„ÙˆÙ…'] - df_filtered_copy['Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø¢Ø¯Ø§Ø¨']
    
    science_tilt = len(df_filtered_copy[df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] > 0.5])
    humanities_tilt = len(df_filtered_copy[df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] < -0.5])
    balanced = len(df_filtered_copy[(df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] >= -0.5) & (df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] <= 0.5)])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ”¬ ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù…ÙŠÙˆÙ†", science_tilt, help="ØªÙ„Ø§Ù…ÙŠØ° Ø£Ø¯Ø§Ø¤Ù‡Ù… Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø¹Ù„ÙˆÙ… Ø¨ÙØ§Ø±Ù‚ > 0.5")
    with col2:
        st.metric("âš–ï¸ ØªÙ„Ø§Ù…ÙŠØ° Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ†", balanced, help="ØªÙ„Ø§Ù…ÙŠØ° Ù…ØªÙ‚Ø§Ø±Ø¨ÙˆÙ† ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡")
    with col3:
        st.metric("ğŸ“š ØªÙ„Ø§Ù…ÙŠØ° Ø£Ø¯Ø¨ÙŠÙˆÙ†", humanities_tilt, help="ØªÙ„Ø§Ù…ÙŠØ° Ø£Ø¯Ø§Ø¤Ù‡Ù… Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø¢Ø¯Ø§Ø¨ Ø¨ÙØ§Ø±Ù‚ > 0.5")

st.markdown("---")

# Enrichment Subjects Analysis (Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­)
st.header("ğŸ¨ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ ÙˆØ¹Ù„Ø§Ù‚ØªÙ‡Ø§ Ø¨Ø§Ù„ØªÙˆØ¬Ù‡")

st.markdown("""
**ØªØ­Ù„ÙŠÙ„ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­:** Ù‡Ù„ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø¹Ù„Ù…ÙŠÙˆÙ† Ø£Ùˆ Ø§Ù„Ø£Ø¯Ø¨ÙŠÙˆÙ† Ø£ÙØ¶Ù„ ÙÙŠ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ØŸ
""")

# Define enrichment subjects
enrichment_subjects = ['Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©', 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¨Ø¯Ù†ÙŠØ©', 'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…ÙŠØ§Øª']

# Calculate enrichment average
enrichment_scores = []
for col in enrichment_subjects:
    if col in df_filtered.columns:
        valid_data = df_filtered[col].dropna()
        enrichment_scores.extend(valid_data.tolist())

enrichment_avg = np.mean(enrichment_scores) if enrichment_scores else 0

# Display enrichment subjects overview
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown("### ğŸ¨ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­")
    st.metric("Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø§Ù…", f"{enrichment_avg:.2f}")
    st.caption("Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©ØŒ Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¨Ø¯Ù†ÙŠØ©ØŒ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…ÙŠØ§Øª")

# Individual enrichment subjects
enrichment_avgs = {}
for i, col_name in enumerate(enrichment_subjects):
    if col_name in df_filtered.columns:
        avg = df_filtered[col_name].dropna().mean()
        enrichment_avgs[col_name] = avg
        with [col2, col3, col4][i]:
            emoji = ['ğŸ•Œ', 'ğŸƒ', 'ğŸ’»'][i]
            st.metric(f"{emoji} {col_name}", f"{avg:.2f}")

# Analyze enrichment performance by student orientation
if student_science_avg and student_humanities_avg and len(student_science_avg) == len(student_humanities_avg):
    st.markdown("### ğŸ“Š Ø£Ø¯Ø§Ø¡ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ Ø­Ø³Ø¨ ØªÙˆØ¬Ù‡ Ø§Ù„ØªÙ„Ù…ÙŠØ°")
    
    # Calculate enrichment average for each student
    student_enrichment_avg = []
    for idx, row in df_filtered.iterrows():
        enr_vals = [row[col] for col in enrichment_subjects if col in df_filtered.columns and pd.notna(row.get(col))]
        if enr_vals:
            student_enrichment_avg.append(np.mean(enr_vals))
        else:
            student_enrichment_avg.append(np.nan)
    
    df_filtered_copy['Ù…Ø¹Ø¯Ù„_Ø§Ù„ØªÙØªØ­'] = student_enrichment_avg[:len(df_filtered)]
    
    # Categorize students
    science_students = df_filtered_copy[df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] > 0.5]
    humanities_students = df_filtered_copy[df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] < -0.5]
    balanced_students = df_filtered_copy[(df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] >= -0.5) & (df_filtered_copy['Ø§Ù„ÙØ±Ù‚'] <= 0.5)]
    
    # Calculate enrichment averages by orientation
    science_enrichment = science_students['Ù…Ø¹Ø¯Ù„_Ø§Ù„ØªÙØªØ­'].dropna().mean() if len(science_students) > 0 else 0
    humanities_enrichment = humanities_students['Ù…Ø¹Ø¯Ù„_Ø§Ù„ØªÙØªØ­'].dropna().mean() if len(humanities_students) > 0 else 0
    balanced_enrichment = balanced_students['Ù…Ø¹Ø¯Ù„_Ø§Ù„ØªÙØªØ­'].dropna().mean() if len(balanced_students) > 0 else 0
    
    # Display comparison
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "ğŸ”¬ Ø§Ù„Ø¹Ù„Ù…ÙŠÙˆÙ† ÙÙŠ Ø§Ù„ØªÙØªØ­", 
            f"{science_enrichment:.2f}" if science_enrichment > 0 else "â€”",
            help=f"Ù…Ø¹Ø¯Ù„ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ Ù„Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø°ÙˆÙŠ Ø§Ù„ØªÙˆØ¬Ù‡ Ø§Ù„Ø¹Ù„Ù…ÙŠ ({len(science_students)} ØªÙ„Ù…ÙŠØ°)"
        )
    
    with col2:
        st.metric(
            "âš–ï¸ Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ† ÙÙŠ Ø§Ù„ØªÙØªØ­", 
            f"{balanced_enrichment:.2f}" if balanced_enrichment > 0 else "â€”",
            help=f"Ù…Ø¹Ø¯Ù„ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ Ù„Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†ÙŠÙ† ({len(balanced_students)} ØªÙ„Ù…ÙŠØ°)"
        )
    
    with col3:
        st.metric(
            "ğŸ“š Ø§Ù„Ø£Ø¯Ø¨ÙŠÙˆÙ† ÙÙŠ Ø§Ù„ØªÙØªØ­", 
            f"{humanities_enrichment:.2f}" if humanities_enrichment > 0 else "â€”",
            help=f"Ù…Ø¹Ø¯Ù„ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ Ù„Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø°ÙˆÙŠ Ø§Ù„ØªÙˆØ¬Ù‡ Ø§Ù„Ø£Ø¯Ø¨ÙŠ ({len(humanities_students)} ØªÙ„Ù…ÙŠØ°)"
        )
    
    # Visualization
    col1, col2 = st.columns(2)
    
    with col1:
        # Bar chart for enrichment by orientation
        orientation_enrichment_df = pd.DataFrame({
            'Ø§Ù„ØªÙˆØ¬Ù‡': ['ğŸ”¬ Ø¹Ù„Ù…ÙŠÙˆÙ†', 'âš–ï¸ Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ†', 'ğŸ“š Ø£Ø¯Ø¨ÙŠÙˆÙ†'],
            'Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙØªØ­': [science_enrichment, balanced_enrichment, humanities_enrichment],
            'Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°': [len(science_students), len(balanced_students), len(humanities_students)]
        })
        
        fig = px.bar(
            orientation_enrichment_df,
            x='Ø§Ù„ØªÙˆØ¬Ù‡',
            y='Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙØªØ­',
            color='Ø§Ù„ØªÙˆØ¬Ù‡',
            color_discrete_map={
                'ğŸ”¬ Ø¹Ù„Ù…ÙŠÙˆÙ†': '#636EFA',
                'âš–ï¸ Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ†': '#00CC96',
                'ğŸ“š Ø£Ø¯Ø¨ÙŠÙˆÙ†': '#EF553B'
            },
            text='Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙØªØ­'
        )
        fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')
        fig.update_layout(height=400, showlegend=False, title="Ù…Ø¹Ø¯Ù„ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ Ø­Ø³Ø¨ Ø§Ù„ØªÙˆØ¬Ù‡")
        fig.add_hline(y=10, line_dash="dash", line_color="green", annotation_text="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # Detailed enrichment subjects by orientation
        detailed_data = []
        for subj in enrichment_subjects:
            if subj in df_filtered.columns:
                sci_avg = science_students[subj].dropna().mean() if len(science_students) > 0 else 0
                hum_avg = humanities_students[subj].dropna().mean() if len(humanities_students) > 0 else 0
                bal_avg = balanced_students[subj].dropna().mean() if len(balanced_students) > 0 else 0
                
                detailed_data.append({'Ø§Ù„Ù…Ø§Ø¯Ø©': subj, 'Ø§Ù„Ù…Ø¹Ø¯Ù„': sci_avg, 'Ø§Ù„ØªÙˆØ¬Ù‡': 'Ø¹Ù„Ù…ÙŠÙˆÙ†'})
                detailed_data.append({'Ø§Ù„Ù…Ø§Ø¯Ø©': subj, 'Ø§Ù„Ù…Ø¹Ø¯Ù„': hum_avg, 'Ø§Ù„ØªÙˆØ¬Ù‡': 'Ø£Ø¯Ø¨ÙŠÙˆÙ†'})
                detailed_data.append({'Ø§Ù„Ù…Ø§Ø¯Ø©': subj, 'Ø§Ù„Ù…Ø¹Ø¯Ù„': bal_avg, 'Ø§Ù„ØªÙˆØ¬Ù‡': 'Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ†'})
        
        if detailed_data:
            detailed_df = pd.DataFrame(detailed_data)
            fig = px.bar(
                detailed_df,
                x='Ø§Ù„Ù…Ø§Ø¯Ø©',
                y='Ø§Ù„Ù…Ø¹Ø¯Ù„',
                color='Ø§Ù„ØªÙˆØ¬Ù‡',
                barmode='group',
                color_discrete_map={
                    'Ø¹Ù„Ù…ÙŠÙˆÙ†': '#636EFA',
                    'Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ†': '#00CC96',
                    'Ø£Ø¯Ø¨ÙŠÙˆÙ†': '#EF553B'
                }
            )
            fig.update_layout(height=400, title="ØªÙØµÙŠÙ„ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ Ø­Ø³Ø¨ Ø§Ù„ØªÙˆØ¬Ù‡")
            st.plotly_chart(fig, use_container_width=True)
    
    # Insights
    st.markdown("### ğŸ’¡ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­")
    
    # Determine who performs better
    best_in_enrichment = max(
        [('Ø§Ù„Ø¹Ù„Ù…ÙŠÙˆÙ†', science_enrichment), ('Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ†', balanced_enrichment), ('Ø§Ù„Ø£Ø¯Ø¨ÙŠÙˆÙ†', humanities_enrichment)],
        key=lambda x: x[1] if x[1] > 0 else -999
    )
    
    worst_in_enrichment = min(
        [('Ø§Ù„Ø¹Ù„Ù…ÙŠÙˆÙ†', science_enrichment), ('Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ†', balanced_enrichment), ('Ø§Ù„Ø£Ø¯Ø¨ÙŠÙˆÙ†', humanities_enrichment)],
        key=lambda x: x[1] if x[1] > 0 else 999
    )
    
    if best_in_enrichment[1] > 0 and worst_in_enrichment[1] > 0:
        diff_enrichment = best_in_enrichment[1] - worst_in_enrichment[1]
        
        if diff_enrichment < 0.3:
            st.success("âœ… **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…ØªÙ‚Ø§Ø±Ø¨:** Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø¨Ù…Ø®ØªÙ„Ù ØªÙˆØ¬Ù‡Ø§ØªÙ‡Ù… Ù„Ø¯ÙŠÙ‡Ù… Ø£Ø¯Ø§Ø¡ Ù…ØªØ´Ø§Ø¨Ù‡ ÙÙŠ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­.")
        else:
            st.info(f"ğŸ“Š **{best_in_enrichment[0]}** Ù‡Ù… Ø§Ù„Ø£ÙØ¶Ù„ ÙÙŠ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ Ø¨Ù…Ø¹Ø¯Ù„ **{best_in_enrichment[1]:.2f}**ØŒ Ù…ØªÙÙˆÙ‚ÙŠÙ† Ø¹Ù„Ù‰ {worst_in_enrichment[0]} Ø¨ÙØ§Ø±Ù‚ **{diff_enrichment:.2f}** Ù†Ù‚Ø·Ø©.")
        
        # Individual subject insights
        for subj in enrichment_subjects:
            if subj in df_filtered.columns:
                sci_avg = science_students[subj].dropna().mean() if len(science_students) > 0 else 0
                hum_avg = humanities_students[subj].dropna().mean() if len(humanities_students) > 0 else 0
                
                if sci_avg > 0 and hum_avg > 0:
                    subj_diff = sci_avg - hum_avg
                    if abs(subj_diff) >= 0.5:
                        if subj_diff > 0:
                            st.caption(f"ğŸ”¬ **{subj}:** Ø§Ù„Ø¹Ù„Ù…ÙŠÙˆÙ† Ø£ÙØ¶Ù„ Ø¨ÙØ§Ø±Ù‚ {subj_diff:.2f}")
                        else:
                            st.caption(f"ğŸ“š **{subj}:** Ø§Ù„Ø£Ø¯Ø¨ÙŠÙˆÙ† Ø£ÙØ¶Ù„ Ø¨ÙØ§Ø±Ù‚ {abs(subj_diff):.2f}")

st.markdown("---")

# Language Proficiency Gap Analysis
st.header("ğŸŒ ØªØ­Ù„ÙŠÙ„ ÙØ¬ÙˆØ© Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù„ØºÙˆÙŠØ©")

st.markdown("""
**Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù„ØºÙˆÙŠ:** Ù‡Ù„ ÙŠÙˆØ§Ø¬Ù‡ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù„ØºØªÙ‡Ù… Ø§Ù„Ø£Ù…ØŸ
""")

# Define language subjects
primary_language = 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©'
foreign_languages = ['Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©']

# Calculate averages
arabic_avg = df_filtered[primary_language].dropna().mean() if primary_language in df_filtered.columns else 0
french_avg = df_filtered['Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©'].dropna().mean() if 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©' in df_filtered.columns else 0
english_avg = df_filtered['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'].dropna().mean() if 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©' in df_filtered.columns else 0
foreign_avg = np.mean([french_avg, english_avg]) if french_avg > 0 or english_avg > 0 else 0

# Language proficiency gap
proficiency_gap = arabic_avg - foreign_avg

# Display metrics
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.markdown("### ğŸ‡²ğŸ‡¦ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    st.metric("Ø§Ù„Ù…ØªÙˆØ³Ø·", f"{arabic_avg:.2f}")
    st.caption("Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ù…")

with col2:
    st.markdown("### ğŸ‡«ğŸ‡· Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©")
    st.metric("Ø§Ù„Ù…ØªÙˆØ³Ø·", f"{french_avg:.2f}")
    gap_fr = arabic_avg - french_avg
    if gap_fr > 0:
        st.caption(f"ÙØ¬ÙˆØ©: -{gap_fr:.2f}")
    else:
        st.caption(f"ÙØ±Ù‚: +{abs(gap_fr):.2f}")

with col3:
    st.markdown("### ğŸ‡¬ğŸ‡§ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")
    st.metric("Ø§Ù„Ù…ØªÙˆØ³Ø·", f"{english_avg:.2f}")
    gap_en = arabic_avg - english_avg
    if gap_en > 0:
        st.caption(f"ÙØ¬ÙˆØ©: -{gap_en:.2f}")
    else:
        st.caption(f"ÙØ±Ù‚: +{abs(gap_en):.2f}")

with col4:
    st.markdown("### ğŸ“Š ÙØ¬ÙˆØ© Ø§Ù„ÙƒÙØ§Ø¡Ø©")
    if proficiency_gap > 0:
        st.metric("Ø§Ù„ÙØ¬ÙˆØ©", f"{proficiency_gap:.2f}", delta=f"-{proficiency_gap:.2f}", delta_color="inverse")
    else:
        st.metric("Ø§Ù„ÙØ¬ÙˆØ©", f"{abs(proficiency_gap):.2f}", delta=f"+{abs(proficiency_gap):.2f}")
    st.caption("Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©")

# Visualization
col1, col2 = st.columns(2)

with col1:
    # Bar chart for language comparison
    lang_df = pd.DataFrame({
        'Ø§Ù„Ù„ØºØ©': ['ğŸ‡²ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'ğŸ‡«ğŸ‡· Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'ğŸ‡¬ğŸ‡§ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'],
        'Ø§Ù„Ù…ØªÙˆØ³Ø·': [arabic_avg, french_avg, english_avg],
        'Ø§Ù„Ù†ÙˆØ¹': ['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ù…', 'Ù„ØºØ© Ø£Ø¬Ù†Ø¨ÙŠØ©', 'Ù„ØºØ© Ø£Ø¬Ù†Ø¨ÙŠØ©']
    })
    
    fig = px.bar(
        lang_df,
        x='Ø§Ù„Ù„ØºØ©',
        y='Ø§Ù„Ù…ØªÙˆØ³Ø·',
        color='Ø§Ù„Ù†ÙˆØ¹',
        color_discrete_map={
            'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ù…': '#00CC96',
            'Ù„ØºØ© Ø£Ø¬Ù†Ø¨ÙŠØ©': '#EF553B'
        },
        text='Ø§Ù„Ù…ØªÙˆØ³Ø·'
    )
    fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')
    fig.update_layout(height=400, showlegend=True, title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù„ØºÙˆÙŠ")
    fig.add_hline(y=10, line_dash="dash", line_color="gray", annotation_text="Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­")
    st.plotly_chart(fig, use_container_width=True)

with col2:
    # Radar chart for language skills
    categories = ['Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©']
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=[arabic_avg, french_avg, english_avg],
        theta=categories,
        fill='toself',
        name='Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„ÙØ¹Ù„ÙŠ',
        line_color='#636EFA'
    ))
    
    # Add reference line for passing grade
    fig.add_trace(go.Scatterpolar(
        r=[10, 10, 10],
        theta=categories,
        fill='toself',
        name='Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­',
        line_color='#00CC96',
        opacity=0.3
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 20]
            )
        ),
        showlegend=True,
        title="Ù…Ø®Ø·Ø· Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù„ØºÙˆÙŠØ©",
        height=400
    )
    st.plotly_chart(fig, use_container_width=True)

# Per-student language gap analysis
st.markdown("### ğŸ“ˆ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ© Ù„Ø¯Ù‰ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°")

student_arabic = []
student_foreign = []
student_gap = []

for idx, row in df_filtered.iterrows():
    ar = row.get(primary_language) if primary_language in df_filtered.columns else np.nan
    fr = row.get('Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©') if 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©' in df_filtered.columns else np.nan
    en = row.get('Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©') if 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©' in df_filtered.columns else np.nan
    
    if pd.notna(ar):
        student_arabic.append(ar)
        foreign_vals = [v for v in [fr, en] if pd.notna(v)]
        if foreign_vals:
            foreign_mean = np.mean(foreign_vals)
            student_foreign.append(foreign_mean)
            student_gap.append(ar - foreign_mean)
        else:
            student_foreign.append(np.nan)
            student_gap.append(np.nan)
    else:
        student_arabic.append(np.nan)
        student_foreign.append(np.nan)
        student_gap.append(np.nan)

# Categorize students by gap
positive_gap = sum(1 for g in student_gap if pd.notna(g) and g > 1)  # Better in Arabic
small_gap = sum(1 for g in student_gap if pd.notna(g) and -1 <= g <= 1)  # Balanced
negative_gap = sum(1 for g in student_gap if pd.notna(g) and g < -1)  # Better in foreign languages

col1, col2, col3 = st.columns(3)

with col1:
    st.metric(
        "ğŸ‡²ğŸ‡¦ Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", 
        positive_gap,
        help="ØªÙ„Ø§Ù…ÙŠØ° Ø£Ø¯Ø§Ø¤Ù‡Ù… ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£ÙØ¶Ù„ Ù…Ù† Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ø¨ÙØ§Ø±Ù‚ > 1"
    )

with col2:
    st.metric(
        "âš–ï¸ Ù…ØªÙˆØ§Ø²Ù†ÙˆÙ† Ù„ØºÙˆÙŠØ§Ù‹", 
        small_gap,
        help="ØªÙ„Ø§Ù…ÙŠØ° Ø£Ø¯Ø§Ø¤Ù‡Ù… Ù…ØªÙ‚Ø§Ø±Ø¨ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù„ØºØ§Øª"
    )

with col3:
    st.metric(
        "ğŸŒ Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©", 
        negative_gap,
        help="ØªÙ„Ø§Ù…ÙŠØ° Ø£Ø¯Ø§Ø¤Ù‡Ù… ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ø£ÙØ¶Ù„ Ù…Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨ÙØ§Ø±Ù‚ > 1"
    )

# Histogram of language gap
if student_gap:
    valid_gaps = [g for g in student_gap if pd.notna(g)]
    if valid_gaps:
        gap_df = pd.DataFrame({'Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ©': valid_gaps})
        fig = px.histogram(
            gap_df,
            x='Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ©',
            nbins=20,
            color_discrete_sequence=['#636EFA']
        )
        fig.add_vline(x=0, line_dash="dash", line_color="red", annotation_text="ØªÙˆØ§Ø²Ù†")
        fig.update_layout(
            title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ© (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©)",
            xaxis_title="Ø§Ù„ÙØ¬ÙˆØ© (Ù‚ÙŠÙ… Ù…ÙˆØ¬Ø¨Ø© = Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)",
            yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°",
            height=350
        )
        st.plotly_chart(fig, use_container_width=True)

# French vs English comparison
st.markdown("### ğŸ‡«ğŸ‡· vs ğŸ‡¬ğŸ‡§ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØªÙŠÙ†")

col1, col2 = st.columns(2)

with col1:
    fr_en_diff = french_avg - english_avg
    if abs(fr_en_diff) < 0.5:
        st.info("âš–ï¸ **Ø£Ø¯Ø§Ø¡ Ù…ØªÙ‚Ø§Ø±Ø¨:** Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ù„Ø¯ÙŠÙ‡Ù… Ù…Ø³ØªÙˆÙ‰ Ù…ØªØ´Ø§Ø¨Ù‡ ÙÙŠ Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.")
    elif fr_en_diff > 0:
        st.info(f"ğŸ‡«ğŸ‡· **Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© Ø£ÙØ¶Ù„:** Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠØªÙÙˆÙ‚ÙˆÙ† ÙÙŠ Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© Ø¨ÙØ§Ø±Ù‚ **{fr_en_diff:.2f}** Ù†Ù‚Ø·Ø©.")
    else:
        st.info(f"ğŸ‡¬ğŸ‡§ **Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø£ÙØ¶Ù„:** Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠØªÙÙˆÙ‚ÙˆÙ† ÙÙŠ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¨ÙØ§Ø±Ù‚ **{abs(fr_en_diff):.2f}** Ù†Ù‚Ø·Ø©.")

with col2:
    # Success rates for each language
    if primary_language in df_filtered.columns:
        ar_pass = (df_filtered[primary_language].dropna() >= 10).mean() * 100
    else:
        ar_pass = 0
    
    if 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©' in df_filtered.columns:
        fr_pass = (df_filtered['Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©'].dropna() >= 10).mean() * 100
    else:
        fr_pass = 0
    
    if 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©' in df_filtered.columns:
        en_pass = (df_filtered['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'].dropna() >= 10).mean() * 100
    else:
        en_pass = 0
    
    pass_df = pd.DataFrame({
        'Ø§Ù„Ù„ØºØ©': ['Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'],
        'Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %': [ar_pass, fr_pass, en_pass]
    })
    
    fig = px.bar(
        pass_df,
        x='Ø§Ù„Ù„ØºØ©',
        y='Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %',
        color='Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %',
        color_continuous_scale='RdYlGn',
        text='Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %'
    )
    fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
    fig.update_layout(height=300, title="Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ ÙƒÙ„ Ù„ØºØ©")
    st.plotly_chart(fig, use_container_width=True)

# Insights
st.markdown("### ğŸ’¡ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù„ØºÙˆÙŠØ©")

if proficiency_gap > 2:
    st.warning(f"âš ï¸ **ÙØ¬ÙˆØ© ÙƒØ¨ÙŠØ±Ø©:** Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠÙˆØ§Ø¬Ù‡ÙˆÙ† ØµØ¹ÙˆØ¨Ø© ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (ÙØ¬ÙˆØ©: {proficiency_gap:.2f}). ÙŠÙÙ†ØµØ­ Ø¨ØªØ¹Ø²ÙŠØ² Ø¨Ø±Ø§Ù…Ø¬ ØªØ¹Ù„Ù… Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©.")
elif proficiency_gap > 1:
    st.info(f"ğŸ“Š **ÙØ¬ÙˆØ© Ù…ØªÙˆØ³Ø·Ø©:** Ù‡Ù†Ø§Ùƒ ÙØ±Ù‚ Ù…Ù„Ø­ÙˆØ¸ Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© (ÙØ¬ÙˆØ©: {proficiency_gap:.2f}).")
elif proficiency_gap > 0:
    st.success(f"âœ… **ÙØ¬ÙˆØ© ØµØºÙŠØ±Ø©:** Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…ØªÙ‚Ø§Ø±Ø¨ Ù†Ø³Ø¨ÙŠØ§Ù‹ Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª (ÙØ¬ÙˆØ©: {proficiency_gap:.2f}).")
else:
    st.success(f"ğŸŒŸ **ØªÙ…ÙŠØ² ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©:** Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠØ¤Ø¯ÙˆÙ† Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ù…Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©!")

# Specific recommendations
if french_avg < 10 or english_avg < 10:
    struggling_langs = []
    if french_avg < 10:
        struggling_langs.append(f"Ø§Ù„ÙØ±Ù†Ø³ÙŠØ© ({french_avg:.2f})")
    if english_avg < 10:
        struggling_langs.append(f"Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ({english_avg:.2f})")
    st.caption(f"âš ï¸ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Ù‹: {', '.join(struggling_langs)}")

st.markdown("---")

# Correlation Analysis
st.header("ğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯")

st.markdown("""
**ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª:** Ù‡Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ù…Ø§Ø¯Ø© Ù…Ø¹ÙŠÙ†Ø© ÙŠØªÙ†Ø¨Ø£ Ø¨Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ù…Ø§Ø¯Ø© Ø£Ø®Ø±Ù‰ØŸ
- **Ø§Ø±ØªØ¨Ø§Ø· Ù‚ÙˆÙŠ (> 0.7):** Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹
- **Ø§Ø±ØªØ¨Ø§Ø· Ù…ØªÙˆØ³Ø· (0.4-0.7):** Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ù…Ø¹ØªØ¯Ù„Ø©
- **Ø§Ø±ØªØ¨Ø§Ø· Ø¶Ø¹ÙŠÙ (< 0.4):** Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¶Ø¹ÙŠÙØ©
""")

# Get available subjects for correlation
correlation_subjects = [col for col in subject_columns if col in df_filtered.columns and col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„']
correlation_data = df_filtered[correlation_subjects].dropna()

if len(correlation_data) > 5 and len(correlation_subjects) > 1:
    # Calculate correlation matrix
    corr_matrix = correlation_data.corr()
    
    # Heatmap visualization
    st.markdown("### ğŸ—ºï¸ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø­Ø±Ø§Ø±ÙŠØ©")
    
    fig = px.imshow(
        corr_matrix,
        labels=dict(x="Ø§Ù„Ù…Ø§Ø¯Ø©", y="Ø§Ù„Ù…Ø§Ø¯Ø©", color="Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·"),
        x=correlation_subjects,
        y=correlation_subjects,
        color_continuous_scale='RdBu_r',
        zmin=-1,
        zmax=1,
        aspect='auto'
    )
    fig.update_layout(
        height=500,
        title="Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠØ©"
    )
    # Add correlation values as text
    annotations = []
    for i, row in enumerate(corr_matrix.values):
        for j, val in enumerate(row):
            annotations.append(
                dict(
                    x=j,
                    y=i,
                    text=f"{val:.2f}",
                    showarrow=False,
                    font=dict(color='white' if abs(val) > 0.5 else 'black', size=10)
                )
            )
    fig.update_layout(annotations=annotations)
    st.plotly_chart(fig, use_container_width=True)
    
    # Find strongest correlations (excluding self-correlation)
    st.markdown("### ğŸ“Š Ø£Ù‚ÙˆÙ‰ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯")
    
    # Get upper triangle of correlation matrix (to avoid duplicates)
    correlations = []
    for i in range(len(correlation_subjects)):
        for j in range(i + 1, len(correlation_subjects)):
            correlations.append({
                'Ø§Ù„Ù…Ø§Ø¯Ø© 1': correlation_subjects[i],
                'Ø§Ù„Ù…Ø§Ø¯Ø© 2': correlation_subjects[j],
                'Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·': corr_matrix.iloc[i, j]
            })
    
    corr_df = pd.DataFrame(correlations)
    corr_df['Ù‚ÙˆØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·'] = corr_df['Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·'].abs()
    corr_df = corr_df.sort_values('Ù‚ÙˆØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·', ascending=False)
    
    # Top 5 strongest correlations
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ” Ø£Ù‚ÙˆÙ‰ 5 Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª")
        top_5 = corr_df.head(5)
        for idx, row in top_5.iterrows():
            corr_val = row['Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·']
            if corr_val >= 0.7:
                emoji = "ğŸŸ¢"
                strength = "Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹"
            elif corr_val >= 0.4:
                emoji = "ğŸŸ¡"
                strength = "Ù…ØªÙˆØ³Ø·"
            elif corr_val >= 0:
                emoji = "ğŸŸ "
                strength = "Ø¶Ø¹ÙŠÙ"
            else:
                emoji = "ğŸ”´"
                strength = "Ø¹ÙƒØ³ÙŠ"
            
            st.markdown(f"{emoji} **{row['Ø§Ù„Ù…Ø§Ø¯Ø© 1']}** â†” **{row['Ø§Ù„Ù…Ø§Ø¯Ø© 2']}**: {corr_val:.2f} ({strength})")
    
    with col2:
        st.markdown("#### ğŸ“‰ Ø£Ø¶Ø¹Ù 5 Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª")
        bottom_5 = corr_df.tail(5).iloc[::-1]
        for idx, row in bottom_5.iterrows():
            corr_val = row['Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·']
            if abs(corr_val) < 0.2:
                emoji = "âšª"
                strength = "Ø´Ø¨Ù‡ Ù…Ø¹Ø¯ÙˆÙ…"
            elif corr_val < 0:
                emoji = "ğŸ”´"
                strength = "Ø¹ÙƒØ³ÙŠ"
            else:
                emoji = "ğŸŸ "
                strength = "Ø¶Ø¹ÙŠÙ"
            
            st.markdown(f"{emoji} **{row['Ø§Ù„Ù…Ø§Ø¯Ø© 1']}** â†” **{row['Ø§Ù„Ù…Ø§Ø¯Ø© 2']}**: {corr_val:.2f} ({strength})")
    
    # Subject-specific correlation analysis
    st.markdown("### ğŸ¯ ØªØ­Ù„ÙŠÙ„ Ø§Ø±ØªØ¨Ø§Ø· ÙƒÙ„ Ù…Ø§Ø¯Ø©")
    
    selected_subject = st.selectbox(
        "Ø§Ø®ØªØ± Ù…Ø§Ø¯Ø© Ù„Ø¹Ø±Ø¶ Ø§Ø±ØªØ¨Ø§Ø·Ø§ØªÙ‡Ø§:",
        correlation_subjects,
        key="corr_subject_select"
    )
    
    if selected_subject:
        subject_corr = corr_matrix[selected_subject].drop(selected_subject).sort_values(ascending=False)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Bar chart of correlations
            corr_chart_df = pd.DataFrame({
                'Ø§Ù„Ù…Ø§Ø¯Ø©': subject_corr.index,
                'Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·': subject_corr.values
            })
            
            fig = px.bar(
                corr_chart_df,
                x='Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·',
                y='Ø§Ù„Ù…Ø§Ø¯Ø©',
                orientation='h',
                color='Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·',
                color_continuous_scale='RdBu_r',
                range_color=[-1, 1],
                text='Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·'
            )
            fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')
            fig.update_layout(height=400, title=f"Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª {selected_subject}")
            fig.add_vline(x=0, line_dash="dash", line_color="gray")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Interpretation
            st.markdown(f"#### ğŸ’¡ ØªÙØ³ÙŠØ± Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª {selected_subject}")
            
            strong_positive = subject_corr[subject_corr >= 0.6]
            moderate_positive = subject_corr[(subject_corr >= 0.4) & (subject_corr < 0.6)]
            weak = subject_corr[(subject_corr > -0.4) & (subject_corr < 0.4)]
            negative = subject_corr[subject_corr <= -0.4]
            
            if len(strong_positive) > 0:
                st.success(f"ğŸŸ¢ **Ø§Ø±ØªØ¨Ø§Ø· Ù‚ÙˆÙŠ Ù…Ø¹:** {', '.join(strong_positive.index.tolist())}")
                st.caption("Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø¬ÙŠØ¯ÙˆÙ† ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø¯Ø© ØºØ§Ù„Ø¨Ø§Ù‹ Ø¬ÙŠØ¯ÙˆÙ† ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©")
            
            if len(moderate_positive) > 0:
                st.info(f"ğŸŸ¡ **Ø§Ø±ØªØ¨Ø§Ø· Ù…ØªÙˆØ³Ø· Ù…Ø¹:** {', '.join(moderate_positive.index.tolist())}")
            
            if len(negative) > 0:
                st.warning(f"ğŸ”´ **Ø§Ø±ØªØ¨Ø§Ø· Ø¹ÙƒØ³ÙŠ Ù…Ø¹:** {', '.join(negative.index.tolist())}")
                st.caption("Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø¬ÙŠØ¯ÙˆÙ† ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø¯Ø© Ù‚Ø¯ ÙŠÙˆØ§Ø¬Ù‡ÙˆÙ† ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©")
    
    # Scatter plot for specific pairs
    st.markdown("### ğŸ“ˆ Ø±Ø³Ù… Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± Ø¨ÙŠÙ† Ù…Ø§Ø¯ØªÙŠÙ†")
    
    col1, col2 = st.columns(2)
    with col1:
        subject_x = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ (Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø£ÙÙ‚ÙŠ):", correlation_subjects, key="scatter_x")
    with col2:
        remaining_subjects = [s for s in correlation_subjects if s != subject_x]
        subject_y = st.selectbox("Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© (Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠ):", remaining_subjects, key="scatter_y")
    
    if subject_x and subject_y:
        scatter_data = df_filtered[[subject_x, subject_y, 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']].dropna()
        
        if len(scatter_data) > 0:
            correlation_value = scatter_data[subject_x].corr(scatter_data[subject_y])
            
            fig = px.scatter(
                scatter_data,
                x=subject_x,
                y=subject_y,
                hover_data=['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°'],
                trendline='ols',
                color_discrete_sequence=['#636EFA']
            )
            fig.update_layout(
                height=450,
                title=f"Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† {subject_x} Ùˆ {subject_y} (r = {correlation_value:.2f})"
            )
            # Add quadrant lines at passing grade
            fig.add_hline(y=10, line_dash="dash", line_color="green", opacity=0.5)
            fig.add_vline(x=10, line_dash="dash", line_color="green", opacity=0.5)
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Quadrant analysis
            both_pass = len(scatter_data[(scatter_data[subject_x] >= 10) & (scatter_data[subject_y] >= 10)])
            x_only = len(scatter_data[(scatter_data[subject_x] >= 10) & (scatter_data[subject_y] < 10)])
            y_only = len(scatter_data[(scatter_data[subject_x] < 10) & (scatter_data[subject_y] >= 10)])
            both_fail = len(scatter_data[(scatter_data[subject_x] < 10) & (scatter_data[subject_y] < 10)])
            total = len(scatter_data)
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("âœ… Ù†Ø§Ø¬Ø­ÙˆÙ† ÙÙŠ Ø§Ù„Ø§Ø«Ù†ÙŠÙ†", f"{both_pass} ({both_pass/total*100:.0f}%)")
            with col2:
                st.metric(f"ğŸ“— Ù†Ø§Ø¬Ø­ÙˆÙ† ÙÙŠ {subject_x[:10]}.. ÙÙ‚Ø·", f"{x_only} ({x_only/total*100:.0f}%)")
            with col3:
                st.metric(f"ğŸ“˜ Ù†Ø§Ø¬Ø­ÙˆÙ† ÙÙŠ {subject_y[:10]}.. ÙÙ‚Ø·", f"{y_only} ({y_only/total*100:.0f}%)")
            with col4:
                st.metric("âŒ Ø±Ø§Ø³Ø¨ÙˆÙ† ÙÙŠ Ø§Ù„Ø§Ø«Ù†ÙŠÙ†", f"{both_fail} ({both_fail/total*100:.0f}%)")

    # Insights
    st.markdown("### ğŸ’¡ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·")
    
    # Find the most correlated pair
    if len(corr_df) > 0:
        strongest = corr_df.iloc[0]
        weakest = corr_df.iloc[-1]
        
        avg_correlation = corr_df['Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·'].mean()
        
        if avg_correlation >= 0.5:
            st.success(f"ğŸ¯ **ØªØ±Ø§Ø¨Ø· Ø¹Ø§Ù… Ù‚ÙˆÙŠ:** Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯ Ù‡Ùˆ {avg_correlation:.2f}. Ù‡Ø°Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…ØªÙÙˆÙ‚ÙŠÙ† ÙŠÙ…ÙŠÙ„ÙˆÙ† Ù„Ù„ØªÙÙˆÙ‚ ÙÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…ÙˆØ§Ø¯.")
        elif avg_correlation >= 0.3:
            st.info(f"ğŸ“Š **ØªØ±Ø§Ø¨Ø· Ù…ØªÙˆØ³Ø·:** Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· {avg_correlation:.2f}. Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙˆØ§Ø¯ Ù…ØªØ±Ø§Ø¨Ø·Ø© ÙˆØ§Ù„Ø¨Ø¹Ø¶ Ø§Ù„Ø¢Ø®Ø± Ù…Ø³ØªÙ‚Ù„.")
        else:
            st.warning(f"âš ï¸ **ØªØ±Ø§Ø¨Ø· Ø¶Ø¹ÙŠÙ:** Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· {avg_correlation:.2f}. ÙƒÙ„ Ù…Ø§Ø¯Ø© ØªØªØ·Ù„Ø¨ Ù…Ù‡Ø§Ø±Ø§Øª Ù…Ø®ØªÙ„ÙØ©.")
        
        st.caption(f"ğŸ”— Ø£Ù‚ÙˆÙ‰ Ø¹Ù„Ø§Ù‚Ø©: {strongest['Ø§Ù„Ù…Ø§Ø¯Ø© 1']} â†” {strongest['Ø§Ù„Ù…Ø§Ø¯Ø© 2']} ({strongest['Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·']:.2f})")
        st.caption(f"â›“ï¸ Ø£Ø¶Ø¹Ù Ø¹Ù„Ø§Ù‚Ø©: {weakest['Ø§Ù„Ù…Ø§Ø¯Ø© 1']} â†” {weakest['Ø§Ù„Ù…Ø§Ø¯Ø© 2']} ({weakest['Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·']:.2f})")

else:
    st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª. ÙŠØ¬Ø¨ ØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª 5 ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")

st.markdown("---")

# Individual Gap Analysis - At-Risk Report
st.header("ğŸš¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ© - ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…Ø¹Ø±Ø¶ÙŠÙ† Ù„Ù„Ø®Ø·Ø±")

st.markdown("""
**ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø°ÙŠÙ† ÙŠØ­ØªØ§Ø¬ÙˆÙ† ØªØ¯Ø®Ù„Ø§Ù‹:** ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø­Ø§ÙØ© Ø§Ù„Ù†Ø¬Ø§Ø­ØŒ ÙˆØ§Ù„Ù…ØªÙ…ÙŠØ²ÙŠÙ†ØŒ ÙˆØ§Ù„Ø°ÙŠÙ† ÙŠØ¹Ø§Ù†ÙˆÙ† Ù…Ù† Ø¶Ø¹Ù ÙÙŠ Ù…ÙˆØ§Ø¯ Ù…Ø¹ÙŠÙ†Ø©.
""")

if 'Ø§Ù„Ù…Ø¹Ø¯Ù„' in df_filtered.columns:
    # Calculate statistics for classification
    avg_mean = df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].dropna().mean()
    avg_std = df_filtered['Ø§Ù„Ù…Ø¹Ø¯Ù„'].dropna().std()
    
    # Classify students
    df_analysis = df_filtered[['Ø±.Øª', 'Ø±Ù‚Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„'] + [col for col in subject_columns if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in df_filtered.columns]].copy()
    df_analysis = df_analysis.dropna(subset=['Ø§Ù„Ù…Ø¹Ø¯Ù„'])
    
    # Categories
    borderline_low = df_analysis[(df_analysis['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 9) & (df_analysis['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 10)]
    borderline_high = df_analysis[(df_analysis['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 10) & (df_analysis['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 11)]
    at_risk = df_analysis[df_analysis['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 9]
    excellent = df_analysis[df_analysis['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= avg_mean + 1.5 * avg_std]
    outliers_top = df_analysis[df_analysis['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= avg_mean + 2 * avg_std]
    
    # Summary metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ğŸ”´ Ù…Ø¹Ø±Ø¶ÙˆÙ† Ù„Ù„Ø®Ø·Ø±",
            len(at_risk),
            help="ØªÙ„Ø§Ù…ÙŠØ° Ù…Ø¹Ø¯Ù„Ù‡Ù… Ø£Ù‚Ù„ Ù…Ù† 9 - ÙŠØ­ØªØ§Ø¬ÙˆÙ† ØªØ¯Ø®Ù„Ø§Ù‹ Ø¹Ø§Ø¬Ù„Ø§Ù‹"
        )
    
    with col2:
        st.metric(
            "ğŸŸ¡ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ©",
            len(borderline_low),
            help="ØªÙ„Ø§Ù…ÙŠØ° Ù…Ø¹Ø¯Ù„Ù‡Ù… Ø¨ÙŠÙ† 9 Ùˆ 10 - Ù‚Ø±ÙŠØ¨ÙˆÙ† Ù…Ù† Ø§Ù„Ø±Ø³ÙˆØ¨"
        )
    
    with col3:
        st.metric(
            "ğŸŸ¢ Ù†Ø§Ø¬Ø­ÙˆÙ† Ø¨ØµØ¹ÙˆØ¨Ø©",
            len(borderline_high),
            help="ØªÙ„Ø§Ù…ÙŠØ° Ù…Ø¹Ø¯Ù„Ù‡Ù… Ø¨ÙŠÙ† 10 Ùˆ 11 - Ù†Ø¬Ø­ÙˆØ§ Ù„ÙƒÙ† ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹"
        )
    
    with col4:
        st.metric(
            "â­ Ù…ØªÙ…ÙŠØ²ÙˆÙ†",
            len(excellent),
            help=f"ØªÙ„Ø§Ù…ÙŠØ° Ù…Ø¹Ø¯Ù„Ù‡Ù… Ø£Ø¹Ù„Ù‰ Ù…Ù† {avg_mean + 1.5 * avg_std:.2f}"
        )
    
    # Tab layout for different categories
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”´ Ø§Ù„Ù…Ø¹Ø±Ø¶ÙˆÙ† Ù„Ù„Ø®Ø·Ø±", "ğŸŸ¡ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ©", "â­ Ø§Ù„Ù…ØªÙ…ÙŠØ²ÙˆÙ†", "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¶Ø¹Ù"])
    
    with tab1:
        st.markdown("### ğŸ”´ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…Ø¹Ø±Ø¶ÙˆÙ† Ù„Ù„Ø®Ø·Ø± (Ù…Ø¹Ø¯Ù„ < 9)")
        if len(at_risk) > 0:
            st.warning(f"âš ï¸ ÙŠÙˆØ¬Ø¯ **{len(at_risk)}** ØªÙ„Ø§Ù…ÙŠØ° Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ ØªØ¯Ø®Ù„ Ø¹Ø§Ø¬Ù„!")
            
            for idx, row in at_risk.iterrows():
                with st.expander(f"ğŸ“‹ {row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']} - Ø§Ù„Ù…Ø¹Ø¯Ù„: {row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}"):
                    # Find weakest subjects
                    subject_scores = {}
                    for col in subject_columns:
                        if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in df_filtered.columns and pd.notna(row.get(col)):
                            subject_scores[col] = row[col]
                    
                    if subject_scores:
                        sorted_subjects = sorted(subject_scores.items(), key=lambda x: x[1])
                        
                        st.markdown("**ğŸ”» Ø£Ø¶Ø¹Ù Ø§Ù„Ù…ÙˆØ§Ø¯ (ØªØ­ØªØ§Ø¬ ØªØ¯Ø®Ù„Ø§Ù‹):**")
                        for subj, score in sorted_subjects[:3]:
                            color = "red" if score < 10 else "green"
                            gap = 10 - score
                            st.markdown(f"- **{subj}**: :red[{score:.2f}] (ÙŠØ­ØªØ§Ø¬ +{gap:.2f} Ù„Ù„Ù†Ø¬Ø§Ø­)")
                        
                        # Calculate what's needed
                        current_avg = row['Ø§Ù„Ù…Ø¹Ø¯Ù„']
                        points_needed = (10 - current_avg) * len(subject_scores)
                        st.info(f"ğŸ’¡ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø±ÙØ¹ Ù…Ø¬Ù…ÙˆØ¹ Ù†Ù‚Ø§Ø·Ù‡ Ø¨Ù€ **{points_needed:.1f}** Ù†Ù‚Ø·Ø© Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…Ø¹Ø¯Ù„ 10")
        else:
            st.success("âœ… Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° Ù…Ø¹Ø±Ø¶ÙˆÙ† Ù„Ù„Ø®Ø·Ø±!")
    
    with tab2:
        st.markdown("### ğŸŸ¡ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ© (Ù…Ø¹Ø¯Ù„ 9-10)")
        if len(borderline_low) > 0:
            st.info(f"ğŸ“Š ÙŠÙˆØ¬Ø¯ **{len(borderline_low)}** ØªÙ„Ø§Ù…ÙŠØ° Ù‚Ø±ÙŠØ¨ÙˆÙ† Ø¬Ø¯Ø§Ù‹ Ù…Ù† Ø®Ø· Ø§Ù„Ù†Ø¬Ø§Ø­")
            
            for idx, row in borderline_low.iterrows():
                with st.expander(f"ğŸ“‹ {row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']} - Ø§Ù„Ù…Ø¹Ø¯Ù„: {row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}"):
                    subject_scores = {}
                    for col in subject_columns:
                        if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in df_filtered.columns and pd.notna(row.get(col)):
                            subject_scores[col] = row[col]
                    
                    if subject_scores:
                        sorted_subjects = sorted(subject_scores.items(), key=lambda x: x[1])
                        failing_subjects = [(s, sc) for s, sc in sorted_subjects if sc < 10]
                        
                        if failing_subjects:
                            st.markdown("**ğŸ¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙŠ ØªØ³Ø­Ø¨ Ø§Ù„Ù…Ø¹Ø¯Ù„ Ù„Ù„Ø£Ø³ÙÙ„:**")
                            for subj, score in failing_subjects[:3]:
                                gap = 10 - score
                                st.markdown(f"- **{subj}**: :red[{score:.2f}] (ÙØ¬ÙˆØ©: {gap:.2f})")
                            
                            # Quick win suggestion
                            easiest_fix = failing_subjects[0]
                            st.success(f"ğŸ’¡ **Ø£Ø³Ù‡Ù„ ØªØ­Ø³ÙŠÙ†:** Ø±ÙØ¹ Ø¯Ø±Ø¬Ø© **{easiest_fix[0]}** Ù…Ù† {easiest_fix[1]:.2f} Ø¥Ù„Ù‰ 10 Ø³ÙŠØ±ÙØ¹ Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ù„Ø­ÙˆØ¸")
                        else:
                            st.success("Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø¯ ÙÙˆÙ‚ 10 - Ø§Ù„Ù…Ø¹Ø¯Ù„ Ù…Ù†Ø®ÙØ¶ Ø¨Ø³Ø¨Ø¨ Ø¨Ø¹Ø¶ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† 10")
        else:
            st.success("âœ… Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø­Ø§ÙØ© Ø§Ù„Ø±Ø³ÙˆØ¨!")
        
        # Also show borderline successful students
        st.markdown("### ğŸŸ¢ Ù†Ø§Ø¬Ø­ÙˆÙ† Ù„ÙƒÙ† ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹ (Ù…Ø¹Ø¯Ù„ 10-11)")
        if len(borderline_high) > 0:
            st.info(f"ğŸ“Š ÙŠÙˆØ¬Ø¯ **{len(borderline_high)}** ØªÙ„Ø§Ù…ÙŠØ° Ù†Ø¬Ø­ÙˆØ§ Ø¨ÙØ§Ø±Ù‚ Ø¨Ø³ÙŠØ·")
            
            borderline_high_sorted = borderline_high.sort_values('Ø§Ù„Ù…Ø¹Ø¯Ù„')
            for idx, row in borderline_high_sorted.head(5).iterrows():
                subject_scores = {col: row[col] for col in subject_columns 
                                if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in df_filtered.columns and pd.notna(row.get(col))}
                if subject_scores:
                    weakest = min(subject_scores.items(), key=lambda x: x[1])
                    st.caption(f"â€¢ {row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']} ({row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}) - Ø£Ø¶Ø¹Ù Ù…Ø§Ø¯Ø©: {weakest[0]} ({weakest[1]:.2f})")
    
    with tab3:
        st.markdown("### â­ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…ØªÙ…ÙŠØ²ÙˆÙ† - Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙÙˆÙ‚")
        
        if len(excellent) > 0:
            st.success(f"ğŸŒŸ ÙŠÙˆØ¬Ø¯ **{len(excellent)}** ØªÙ„Ø§Ù…ÙŠØ° Ù…ØªÙ…ÙŠØ²ÙŠÙ† ÙŠÙ…ÙƒÙ† Ø§Ø¹ØªØ¨Ø§Ø±Ù‡Ù… Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹!")
            
            # Top performers
            top_students = excellent.nlargest(5, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')
            
            for idx, row in top_students.iterrows():
                with st.expander(f"ğŸ† {row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']} - Ø§Ù„Ù…Ø¹Ø¯Ù„: {row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}", expanded=True):
                    subject_scores = {}
                    for col in subject_columns:
                        if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in df_filtered.columns and pd.notna(row.get(col)):
                            subject_scores[col] = row[col]
                    
                    if subject_scores:
                        sorted_subjects = sorted(subject_scores.items(), key=lambda x: x[1], reverse=True)
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.markdown("**ğŸ’ª Ø£Ù‚ÙˆÙ‰ Ø§Ù„Ù…ÙˆØ§Ø¯:**")
                            for subj, score in sorted_subjects[:3]:
                                st.markdown(f"- **{subj}**: :green[{score:.2f}]")
                        
                        with col2:
                            st.markdown("**ğŸ“ˆ Ù…Ø¬Ø§Ù„ Ù„Ù„ØªØ­Ø³ÙŠÙ†:**")
                            for subj, score in sorted_subjects[-2:]:
                                st.markdown(f"- **{subj}**: {score:.2f}")
            
            # Outlier analysis
            if len(outliers_top) > 0:
                st.markdown("### ğŸš€ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠÙˆÙ† (Outliers)")
                st.info(f"Ù‡Ø¤Ù„Ø§Ø¡ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ({len(outliers_top)}) ÙŠØªÙÙˆÙ‚ÙˆÙ† Ø¨Ø´ÙƒÙ„ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ Ø¹Ù„Ù‰ Ø²Ù…Ù„Ø§Ø¦Ù‡Ù…")
                
                for idx, row in outliers_top.iterrows():
                    gap_from_avg = row['Ø§Ù„Ù…Ø¹Ø¯Ù„'] - avg_mean
                    st.caption(f"ğŸŒŸ **{row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']}**: {row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f} (+{gap_from_avg:.2f} Ø¹Ù† Ø§Ù„Ù…ØªÙˆØ³Ø·)")
        else:
            st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° Ù…ØªÙ…ÙŠØ²ÙˆÙ† Ø¨Ø´ÙƒÙ„ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©")
    
    with tab4:
        st.markdown("### ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©")
        
        # Find subjects where most students struggle
        subject_failure_analysis = []
        for col in subject_columns:
            if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in df_filtered.columns:
                subject_data = df_filtered[col].dropna()
                if len(subject_data) > 0:
                    failing_count = (subject_data < 10).sum()
                    failing_pct = (subject_data < 10).mean() * 100
                    avg_score = subject_data.mean()
                    subject_failure_analysis.append({
                        'Ø§Ù„Ù…Ø§Ø¯Ø©': col,
                        'Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø§Ø³Ø¨ÙŠÙ†': failing_count,
                        'Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨ %': failing_pct,
                        'Ø§Ù„Ù…ØªÙˆØ³Ø·': avg_score
                    })
        
        if subject_failure_analysis:
            failure_df = pd.DataFrame(subject_failure_analysis)
            failure_df = failure_df.sort_values('Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨ %', ascending=False)
            
            # Visualization
            fig = px.bar(
                failure_df,
                x='Ø§Ù„Ù…Ø§Ø¯Ø©',
                y='Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨ %',
                color='Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨ %',
                color_continuous_scale='RdYlGn_r',
                text='Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø§Ø³Ø¨ÙŠÙ†'
            )
            fig.update_traces(texttemplate='%{text} ØªÙ„Ù…ÙŠØ°', textposition='outside')
            fig.update_layout(height=400, title="Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨ ÙÙŠ ÙƒÙ„ Ù…Ø§Ø¯Ø©")
            fig.add_hline(y=50, line_dash="dash", line_color="red", annotation_text="Ø®Ø· Ø§Ù„Ø®Ø·Ø± (50%)")
            st.plotly_chart(fig, use_container_width=True)
            
            # Critical subjects
            critical_subjects = failure_df[failure_df['Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨ %'] > 50]
            if len(critical_subjects) > 0:
                st.error(f"âš ï¸ **Ù…ÙˆØ§Ø¯ Ø­Ø±Ø¬Ø©** (Ø£ÙƒØ«Ø± Ù…Ù† 50% Ø±Ø³ÙˆØ¨): {', '.join(critical_subjects['Ø§Ù„Ù…Ø§Ø¯Ø©'].tolist())}")
            
            # Students who fail in multiple subjects
            st.markdown("### ğŸ“‰ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø°ÙŠÙ† ÙŠØ±Ø³Ø¨ÙˆÙ† ÙÙŠ Ø¹Ø¯Ø© Ù…ÙˆØ§Ø¯")
            
            multi_fail_students = []
            for idx, row in df_analysis.iterrows():
                failing_subjects = []
                for col in subject_columns:
                    if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in df_filtered.columns and pd.notna(row.get(col)):
                        if row[col] < 10:
                            failing_subjects.append(col)
                
                if len(failing_subjects) >= 3:
                    multi_fail_students.append({
                        'Ø§Ù„ØªÙ„Ù…ÙŠØ°': row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°'],
                        'Ø§Ù„Ù…Ø¹Ø¯Ù„': row['Ø§Ù„Ù…Ø¹Ø¯Ù„'],
                        'Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø±Ø§Ø³Ø¨ ÙÙŠÙ‡Ø§': len(failing_subjects),
                        'Ø§Ù„Ù…ÙˆØ§Ø¯': ', '.join(failing_subjects[:5])
                    })
            
            if multi_fail_students:
                multi_fail_df = pd.DataFrame(multi_fail_students)
                multi_fail_df = multi_fail_df.sort_values('Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø±Ø§Ø³Ø¨ ÙÙŠÙ‡Ø§', ascending=False)
                
                st.dataframe(multi_fail_df, use_container_width=True, hide_index=True)
                
                worst_case = multi_fail_df.iloc[0]
                st.warning(f"âš ï¸ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø®Ø·ÙˆØ±Ø©: **{worst_case['Ø§Ù„ØªÙ„Ù…ÙŠØ°']}** ÙŠØ±Ø³Ø¨ ÙÙŠ **{worst_case['Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø±Ø§Ø³Ø¨ ÙÙŠÙ‡Ø§']}** Ù…ÙˆØ§Ø¯")
            else:
                st.success("âœ… Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙ„Ø§Ù…ÙŠØ° ÙŠØ±Ø³Ø¨ÙˆÙ† ÙÙŠ 3 Ù…ÙˆØ§Ø¯ Ø£Ùˆ Ø£ÙƒØ«Ø±")

    # Recommendations
    st.markdown("### ğŸ’¡ ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ¯Ø®Ù„")
    
    recommendations = []
    
    if len(at_risk) > 0:
        recommendations.append(f"ğŸ”´ **ØªØ¯Ø®Ù„ Ø¹Ø§Ø¬Ù„:** {len(at_risk)} ØªÙ„Ø§Ù…ÙŠØ° ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹ Ù…ÙƒØ«ÙØ§Ù‹ ÙÙˆØ±ÙŠØ§Ù‹")
    
    if len(borderline_low) > 0:
        recommendations.append(f"ğŸŸ¡ **Ù…ØªØ§Ø¨Ø¹Ø© Ø¯Ù‚ÙŠÙ‚Ø©:** {len(borderline_low)} ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø­Ø§ÙØ© Ø§Ù„Ø±Ø³ÙˆØ¨ ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹ Ù…Ø³ØªÙ‡Ø¯ÙØ§Ù‹")
    
    if len(critical_subjects) > 0 if 'critical_subjects' in dir() else False:
        recommendations.append(f"ğŸ“š **Ù…Ø±Ø§Ø¬Ø¹Ø© Ø·Ø±Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ³:** Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø­Ø±Ø¬Ø© ØªØ­ØªØ§Ø¬ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Ù‹ Ø®Ø§ØµØ§Ù‹")
    
    if len(excellent) > 0:
        recommendations.append(f"â­ **Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªÙ…ÙŠØ²:** {len(excellent)} ØªÙ„Ø§Ù…ÙŠØ° Ù…ØªÙ…ÙŠØ²ÙŠÙ† ÙŠÙ…ÙƒÙ† Ø¥Ø´Ø±Ø§ÙƒÙ‡Ù… ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø²Ù…Ù„Ø§Ø¦Ù‡Ù…")
    
    for rec in recommendations:
        st.markdown(f"- {rec}")

else:
    st.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ 'Ø§Ù„Ù…Ø¹Ø¯Ù„' ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

st.markdown("---")

# Raw Data Table
st.header("ğŸ“‹ Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°")
st.dataframe(df_filtered[['Ø±.Øª', 'Ø±Ù‚Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°'] + subject_columns], 
             use_container_width=True, height=400)

# Download option
st.markdown("---")

col_csv, col_ppt = st.columns(2)

with col_csv:
    # Add UTF-8 BOM for Excel to recognize Arabic characters
    csv = '\ufeff' + df_filtered.to_csv(index=False)
    st.download_button(
        label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ€ CSV",
        data=csv.encode('utf-8'),
        file_name=f"student_data_statistics.csv",
        mime="text/csv"
    )

with col_ppt:
    st.subheader("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø±Ø¶ ØªÙ‚Ø¯ÙŠÙ…ÙŠ")
    
    # Get all available classes
    all_classes = list(df['Ø§Ù„ÙØµÙ„'].unique())
    
    # Option to combine all classes
    combine_all_classes = st.checkbox(
        "Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØµÙˆÙ„ ÙÙŠ Ø¹Ø±Ø¶ ÙˆØ§Ø­Ø¯",
        value=True,
        help="Ø¹Ù†Ø¯ Ø§Ù„ØªÙØ¹ÙŠÙ„ØŒ Ø³ÙŠØªÙ… Ø¯Ù…Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© ÙÙŠ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙˆØ­Ø¯Ø©"
    )
    
    # Multi-select for classes to include in presentation
    selected_classes_ppt = st.multiselect(
        "Ø§Ø®ØªØ± Ø§Ù„ÙØµÙˆÙ„ Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ:",
        options=all_classes,
        default=all_classes,
        help="Ø§Ø®ØªØ± Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ ØªØ¶Ù…ÙŠÙ†Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ"
    )
    
    if len(selected_classes_ppt) == 0:
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± ÙØµÙ„ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„")
    
    # Filter data for presentation based on selected classes
    df_ppt = df[df['Ø§Ù„ÙØµÙ„'].isin(selected_classes_ppt)].copy()
    df_ppt = df_ppt.dropna(subset=['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°'])
    
    # Show summary of selection
    if len(selected_classes_ppt) > 0:
        if combine_all_classes:
            st.info(f"ğŸ“‹ Ø³ÙŠØªÙ… Ø¯Ù…Ø¬ **{len(df_ppt)}** ØªÙ„Ù…ÙŠØ° Ù…Ù† **{len(selected_classes_ppt)}** ÙØµÙ„/ÙØµÙˆÙ„ ÙÙŠ Ø¹Ø±Ø¶ ÙˆØ§Ø­Ø¯")
        else:
            st.info(f"ğŸ“‹ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¹Ø±Ø¶ Ù…Ù†ÙØµÙ„ Ù„ÙƒÙ„ ÙØµÙ„ (**{len(selected_classes_ppt)}** ÙØµÙ„/ÙØµÙˆÙ„)")
    
    if st.button("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ (PPTX)", disabled=len(selected_classes_ppt) == 0):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ..."):
            # Check Kaleido availability early and warn user
            try:
                import kaleido
                test_fig = go.Figure()
                test_fig.to_image(format="png", width=100, height=100)
                kaleido_available = True
            except Exception:
                kaleido_available = False
                st.warning("âš ï¸ ØªØµØ¯ÙŠØ± Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© ØºÙŠØ± Ù…ØªØ§Ø­ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø§Ø¯Ù…. Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©.")
            
            # Create presentation
            prs = Presentation()
            prs.slide_width = Inches(13.333)
            prs.slide_height = Inches(7.5)
            
            # Import additional modules for animations and styling
            from pptx.oxml.ns import nsmap, qn
            from pptx.oxml import parse_xml
            from pptx.dml.color import RGBColor
            from pptx.enum.shapes import MSO_SHAPE
            from lxml import etree
            
            # Helper function to set RTL direction on text frame
            def set_rtl(text_frame):
                """Set Right-to-Left direction on text frame for Arabic"""
                try:
                    for paragraph in text_frame.paragraphs:
                        pPr = paragraph._p.get_or_add_pPr()
                        pPr.set(qn('a:rtl'), '1')
                except Exception:
                    pass
            
            # Helper function to set RTL on paragraph
            def set_paragraph_rtl(paragraph):
                """Set Right-to-Left direction on a paragraph"""
                try:
                    pPr = paragraph._p.get_or_add_pPr()
                    pPr.set(qn('a:rtl'), '1')
                except Exception:
                    pass
            
            # Define color schemes for fancy styling
            PRIMARY_COLOR = RGBColor(0, 112, 192)      # Blue
            SECONDARY_COLOR = RGBColor(0, 176, 80)    # Green
            ACCENT_COLOR = RGBColor(255, 192, 0)      # Gold
            DARK_COLOR = RGBColor(44, 62, 80)         # Dark blue-gray
            LIGHT_COLOR = RGBColor(236, 240, 241)     # Light gray
            
            # Helper function to add gradient background to slide
            def add_gradient_background(slide, color1, color2, angle=90):
                """Add gradient background to slide"""
                try:
                    background = slide.background
                    fill = background.fill
                    fill.gradient()
                    fill.gradient_angle = angle
                    fill.gradient_stops[0].color.rgb = color1
                    fill.gradient_stops[1].color.rgb = color2
                except Exception:
                    pass  # Skip if gradient fails
            
            # Helper function to add decorative shape (simplified without transparency XML)
            def add_decorative_shape(slide, shape_type, left, top, width, height, color, transparency=0.3):
                """Add decorative shape"""
                try:
                    shape = slide.shapes.add_shape(shape_type, left, top, width, height)
                    shape.fill.solid()
                    shape.fill.fore_color.rgb = color
                    shape.line.fill.background()
                    # Use built-in transparency setting
                    shape.fill.fore_color.brightness = transparency
                except Exception:
                    pass
            
            # Helper function to add title slide with fancy styling
            def add_title_slide(prs, title, subtitle=""):
                slide_layout = prs.slide_layouts[6]  # Blank layout
                slide = prs.slides.add_slide(slide_layout)
                
                # Add gradient background
                add_gradient_background(slide, RGBColor(25, 55, 95), RGBColor(45, 85, 135))
                
                # Add decorative circles
                add_decorative_shape(slide, MSO_SHAPE.OVAL, Inches(-2), Inches(-2), Inches(6), Inches(6), 
                                    RGBColor(255, 255, 255), 0.9)
                add_decorative_shape(slide, MSO_SHAPE.OVAL, Inches(10), Inches(4), Inches(5), Inches(5), 
                                    RGBColor(255, 255, 255), 0.92)
                
                # Add accent bar at top
                top_bar = slide.shapes.add_shape(MSO_SHAPE.RECTANGLE, Inches(0), Inches(0), 
                                                  Inches(13.333), Inches(0.15))
                top_bar.fill.solid()
                top_bar.fill.fore_color.rgb = ACCENT_COLOR
                top_bar.line.fill.background()
                
                # Title with shadow effect (white text on dark background)
                title_box = slide.shapes.add_textbox(Inches(0.5), Inches(2.3), Inches(12.333), Inches(1.5))
                title_frame = title_box.text_frame
                title_para = title_frame.paragraphs[0]
                title_para.text = title
                title_para.font.size = Pt(48)
                title_para.font.bold = True
                title_para.font.color.rgb = RGBColor(255, 255, 255)
                title_para.alignment = PP_ALIGN.CENTER
                set_paragraph_rtl(title_para)
                
                if subtitle:
                    subtitle_box = slide.shapes.add_textbox(Inches(0.5), Inches(4.2), Inches(12.333), Inches(1))
                    sub_frame = subtitle_box.text_frame
                    sub_para = sub_frame.paragraphs[0]
                    sub_para.text = subtitle
                    sub_para.font.size = Pt(24)
                    sub_para.font.color.rgb = RGBColor(200, 220, 240)
                    sub_para.alignment = PP_ALIGN.CENTER
                    set_paragraph_rtl(sub_para)
                
                # Add bottom accent line
                bottom_line = slide.shapes.add_shape(MSO_SHAPE.RECTANGLE, Inches(4), Inches(5.5), 
                                                      Inches(5.333), Inches(0.05))
                bottom_line.fill.solid()
                bottom_line.fill.fore_color.rgb = ACCENT_COLOR
                bottom_line.line.fill.background()
                
                return slide
            
            # Helper function to add content slide with fancy styling
            def add_content_slide(prs, title):
                slide_layout = prs.slide_layouts[6]  # Blank layout
                slide = prs.slides.add_slide(slide_layout)
                
                # Add subtle gradient background
                add_gradient_background(slide, RGBColor(248, 249, 250), RGBColor(233, 236, 239))
                
                # Add colored header bar
                header_bar = slide.shapes.add_shape(MSO_SHAPE.RECTANGLE, Inches(0), Inches(0), 
                                                     Inches(13.333), Inches(1.1))
                header_bar.fill.solid()
                header_bar.fill.fore_color.rgb = PRIMARY_COLOR
                header_bar.line.fill.background()
                
                # Add accent stripe
                accent_stripe = slide.shapes.add_shape(MSO_SHAPE.RECTANGLE, Inches(0), Inches(1.1), 
                                                        Inches(13.333), Inches(0.08))
                accent_stripe.fill.solid()
                accent_stripe.fill.fore_color.rgb = ACCENT_COLOR
                accent_stripe.line.fill.background()
                
                # Title with white text on colored header - RTL aligned
                title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.25), Inches(12.333), Inches(0.8))
                title_frame = title_box.text_frame
                title_para = title_frame.paragraphs[0]
                title_para.text = title
                title_para.font.size = Pt(32)
                title_para.font.bold = True
                title_para.font.color.rgb = RGBColor(255, 255, 255)
                title_para.alignment = PP_ALIGN.RIGHT
                set_paragraph_rtl(title_para)
                
                # Add decorative corner shape - moved to left for RTL
                corner_shape = slide.shapes.add_shape(MSO_SHAPE.RIGHT_TRIANGLE, Inches(0), Inches(6), 
                                                       Inches(1.333), Inches(1.5))
                corner_shape.fill.solid()
                corner_shape.fill.fore_color.rgb = PRIMARY_COLOR
                corner_shape.line.fill.background()
                corner_shape.rotation = 270
                
                return slide
            
            # Check if Kaleido/Chrome is available for image export
            def check_kaleido_available():
                try:
                    import kaleido
                    # Try a simple test
                    test_fig = go.Figure()
                    test_fig.to_image(format="png", width=100, height=100)
                    return True
                except Exception:
                    return False
            
            KALEIDO_AVAILABLE = check_kaleido_available()
            
            # Helper to save plotly figure as image
            def fig_to_image(fig):
                if not KALEIDO_AVAILABLE:
                    return None
                try:
                    img_bytes = fig.to_image(format="png", width=900, height=500, scale=2)
                    return io.BytesIO(img_bytes)
                except Exception:
                    return None
            
            # Helper function to add table of contents slide
            def add_toc_slide(prs):
                slide_layout = prs.slide_layouts[6]  # Blank layout
                slide = prs.slides.add_slide(slide_layout)
                
                # Add gradient background
                add_gradient_background(slide, RGBColor(248, 249, 250), RGBColor(233, 236, 239))
                
                # Add side accent bar - on the RIGHT for RTL
                side_bar = slide.shapes.add_shape(MSO_SHAPE.RECTANGLE, Inches(13.033), Inches(0), 
                                                   Inches(0.3), Inches(7.5))
                side_bar.fill.solid()
                side_bar.fill.fore_color.rgb = PRIMARY_COLOR
                side_bar.line.fill.background()
                
                # Title with styled background
                title_bg = slide.shapes.add_shape(MSO_SHAPE.ROUNDED_RECTANGLE, Inches(0.5), Inches(0.3), 
                                                   Inches(12.333), Inches(0.9))
                title_bg.fill.solid()
                title_bg.fill.fore_color.rgb = PRIMARY_COLOR
                title_bg.line.fill.background()
                
                title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.4), Inches(12.333), Inches(0.8))
                title_frame = title_box.text_frame
                title_para = title_frame.paragraphs[0]
                title_para.text = "ğŸ“‹ ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª"
                title_para.font.size = Pt(36)
                title_para.font.bold = True
                title_para.font.color.rgb = RGBColor(255, 255, 255)
                title_para.alignment = PP_ALIGN.CENTER
                set_paragraph_rtl(title_para)
                
                # Table of contents items - RTL layout (right to left columns)
                toc_items = [
                    ("1", "ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©", PRIMARY_COLOR),
                    ("2", "ğŸ† Ø£ÙØ¶Ù„ ÙˆØ£Ø¶Ø¹Ù Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°", SECONDARY_COLOR),
                    ("3", "ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª", PRIMARY_COLOR),
                    ("4", "ğŸ“š Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©", SECONDARY_COLOR),
                    ("5", "ğŸ”¬ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„Ø¢Ø¯Ø§Ø¨", PRIMARY_COLOR),
                    ("6", "ï¿½ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­", SECONDARY_COLOR),
                    ("7", "ğŸŒ Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù„ØºÙˆÙŠØ©", PRIMARY_COLOR),
                    ("8", "ğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·", SECONDARY_COLOR),
                    ("9", "ğŸš¨ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…Ø¹Ø±Ø¶ÙŠÙ† Ù„Ù„Ø®Ø·Ø±", PRIMARY_COLOR),
                    ("10", "ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª", SECONDARY_COLOR)
                ]
                
                # Create two-column RTL layout for TOC items (right column first)
                y_start = 1.5
                x_right = 7.0   # Right column (first in RTL)
                x_left = 0.8    # Left column (second in RTL)
                item_height = 0.5
                
                for i, (num, text, color) in enumerate(toc_items):
                    # RTL: first 5 items on RIGHT, next 5 on LEFT
                    if i < 5:
                        x_pos = x_right
                        y_pos = y_start + (i * item_height)
                    else:
                        x_pos = x_left
                        y_pos = y_start + ((i - 5) * item_height)
                    
                    # Item text FIRST (on the right side) for RTL
                    item_box = slide.shapes.add_textbox(Inches(x_pos), Inches(y_pos + 0.05), 
                                                         Inches(5.0), Inches(0.4))
                    item_frame = item_box.text_frame
                    item_para = item_frame.paragraphs[0]
                    item_para.text = text
                    item_para.font.size = Pt(18)
                    item_para.font.color.rgb = DARK_COLOR
                    item_para.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(item_para)
                    
                    # Number circle AFTER text (on the left) for RTL
                    circle = slide.shapes.add_shape(MSO_SHAPE.OVAL, Inches(x_pos + 5.1), Inches(y_pos), 
                                                     Inches(0.4), Inches(0.4))
                    circle.fill.solid()
                    circle.fill.fore_color.rgb = color
                    circle.line.fill.background()
                    
                    # Number text
                    num_box = slide.shapes.add_textbox(Inches(x_pos + 5.1), Inches(y_pos + 0.05), 
                                                        Inches(0.4), Inches(0.35))
                    num_frame = num_box.text_frame
                    num_para = num_frame.paragraphs[0]
                    num_para.text = num
                    num_para.font.size = Pt(14)
                    num_para.font.bold = True
                    num_para.font.color.rgb = RGBColor(255, 255, 255)
                    num_para.alignment = PP_ALIGN.CENTER
                
                # Add decorative bottom element
                bottom_shape = slide.shapes.add_shape(MSO_SHAPE.RECTANGLE, Inches(2), Inches(6.8), 
                                                       Inches(9.333), Inches(0.05))
                bottom_shape.fill.solid()
                bottom_shape.fill.fore_color.rgb = ACCENT_COLOR
                bottom_shape.line.fill.background()
                
                return slide
            
            # Function to generate slides for a dataset
            def generate_slides_for_data(prs, data_df, title_suffix="", class_names=None):
                if class_names is None:
                    class_names = selected_classes_ppt
                
                # Title slide
                if len(class_names) == 1:
                    classes_text = class_names[0]
                elif len(class_names) <= 3:
                    classes_text = ', '.join(class_names)
                else:
                    classes_text = f"{len(class_names)} ÙØµÙˆÙ„"
                
                add_title_slide(prs, f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° {title_suffix}".strip(), 
                               f"Ø§Ù„ÙØµÙˆÙ„: {classes_text} | Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°: {len(data_df)}")
                
                # Table of Contents
                add_toc_slide(prs)
                
                # Overall Statistics
                slide = add_content_slide(prs, "ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©")
                
                stats_text = f"""
Ø¹Ø¯Ø¯ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°: {len(data_df)}
Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹Ø§Ù…: {data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean():.2f}
Ø£Ø¹Ù„Ù‰ Ù…Ø¹Ø¯Ù„: {data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].max():.2f}
Ø£Ø¯Ù†Ù‰ Ù…Ø¹Ø¯Ù„: {data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].min():.2f}
Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].std():.2f}
Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„: {len(class_names)}
                """
                
                # RTL: Position stats on the right side
                stats_box = slide.shapes.add_textbox(Inches(7.5), Inches(1.5), Inches(5.5), Inches(4))
                stats_frame = stats_box.text_frame
                stats_frame.word_wrap = True
                for line in stats_text.strip().split('\n'):
                    p = stats_frame.add_paragraph()
                    p.text = line.strip()
                    p.font.size = Pt(24)
                    p.space_after = Pt(12)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # Grade Brackets
                slide = add_content_slide(prs, "ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø´Ø±Ø§Ø¦Ø­ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª")
                
                below_avg_count = len(data_df[data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 10])
                avg_count = len(data_df[(data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 10) & (data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 12)])
                good_count = len(data_df[data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 12])
                total = len(data_df)
                
                brackets_text = f"""
ğŸ”´ Ø¯ÙˆÙ† Ø§Ù„Ù…Ø¹Ø¯Ù„ (0 - 9.99): {below_avg_count} ØªÙ„Ù…ÙŠØ° ({below_avg_count/total*100:.1f}%)

ğŸŸ¡ Ù…ØªÙˆØ³Ø· (10 - 11.99): {avg_count} ØªÙ„Ù…ÙŠØ° ({avg_count/total*100:.1f}%)

ğŸŸ¢ Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø² (12 - 20): {good_count} ØªÙ„Ù…ÙŠØ° ({good_count/total*100:.1f}%)

âœ… Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ (â‰¥10): {(avg_count + good_count)/total*100:.1f}%
                """
                
                # RTL: Position brackets text on the right
                bracket_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.5), Inches(6.3), Inches(5))
                bracket_frame = bracket_box.text_frame
                bracket_frame.word_wrap = True
                for line in brackets_text.strip().split('\n'):
                    p = bracket_frame.add_paragraph()
                    p.text = line.strip()
                    p.font.size = Pt(22)
                    p.space_after = Pt(8)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # Pie chart
                bracket_counts_ppt = pd.DataFrame({
                    'Bracket': ['Ø¯ÙˆÙ† Ø§Ù„Ù…Ø¹Ø¯Ù„ (0-9.99)', 'Ù…ØªÙˆØ³Ø· (10-11.99)', 'Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø² (12-20)'],
                    'Count': [below_avg_count, avg_count, good_count]
                })
                fig_pie = px.pie(bracket_counts_ppt, values='Count', names='Bracket',
                                color='Bracket',
                                color_discrete_map={
                                    'Ø¯ÙˆÙ† Ø§Ù„Ù…Ø¹Ø¯Ù„ (0-9.99)': '#EF553B',
                                    'Ù…ØªÙˆØ³Ø· (10-11.99)': '#FECB52',
                                    'Ø¬ÙŠØ¯/Ù…Ù…ØªØ§Ø² (12-20)': '#00CC96'
                                })
                fig_pie.update_traces(textposition='inside', textinfo='percent+value')
                fig_pie.update_layout(showlegend=True, legend=dict(orientation="h", y=-0.1))
                
                img_stream = fig_to_image(fig_pie)
                if img_stream:
                    # RTL: Chart on the left
                    slide.shapes.add_picture(img_stream, Inches(0.5), Inches(1.5), width=Inches(6))
                
                # Average by Subject
                slide = add_content_slide(prs, "ğŸ“š Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©")
                
                stats_data_ppt = []
                for col in subject_columns:
                    if col in data_df.columns:
                        valid_data = data_df[col].dropna()
                        if len(valid_data) > 0:
                            stats_data_ppt.append({
                                'Ø§Ù„Ù…Ø§Ø¯Ø©': col,
                                'Ø§Ù„Ù…ØªÙˆØ³Ø·': valid_data.mean(),
                                'Ø§Ù„Ø£Ø¹Ù„Ù‰': valid_data.max(),
                                'Ø§Ù„Ø£Ù‚Ù„': valid_data.min(),
                                'Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ': valid_data.std(),
                                'Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ù„Ø§Ø¨': len(valid_data)
                            })
                stats_df_ppt = pd.DataFrame(stats_data_ppt)
                
                fig_bar = px.bar(
                    stats_df_ppt.sort_values('Ø§Ù„Ù…ØªÙˆØ³Ø·', ascending=True),
                    x='Ø§Ù„Ù…ØªÙˆØ³Ø·',
                    y='Ø§Ù„Ù…Ø§Ø¯Ø©',
                    orientation='h',
                    color='Ø§Ù„Ù…ØªÙˆØ³Ø·',
                    color_continuous_scale='Viridis'
                )
                fig_bar.update_layout(height=500, width=1100)
                
                img_stream = fig_to_image(fig_bar)
                if img_stream:
                    slide.shapes.add_picture(img_stream, Inches(1), Inches(1.3), width=Inches(11))
                
                # Grade Distribution Histogram
                slide = add_content_slide(prs, "ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª")
                
                fig_hist = px.histogram(
                    data_df,
                    x='Ø§Ù„Ù…Ø¹Ø¯Ù„',
                    nbins=20,
                    color_discrete_sequence=['#636EFA']
                )
                fig_hist.add_vline(data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean(), line_dash="dash", line_color="red",
                                  annotation_text=f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean():.2f}")
                fig_hist.update_layout(height=500, width=1100)
                
                img_stream = fig_to_image(fig_hist)
                if img_stream:
                    slide.shapes.add_picture(img_stream, Inches(1), Inches(1.3), width=Inches(11))
                
                # Box Plot
                slide = add_content_slide(prs, "ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (Ù…Ø®Ø·Ø· ØµÙ†Ø¯ÙˆÙ‚ÙŠ)")
                
                subject_data_ppt_list = []
                for col in subject_columns:
                    if col in data_df.columns:
                        valid_data = data_df[col].dropna()
                        for grade in valid_data:
                            subject_data_ppt_list.append({'Ø§Ù„Ù…Ø§Ø¯Ø©': col, 'Ø§Ù„ØªÙ‚Ø¯ÙŠØ±': grade})
                
                if subject_data_ppt_list:
                    subject_box_df_ppt = pd.DataFrame(subject_data_ppt_list)
                    fig_box = px.box(subject_box_df_ppt, x='Ø§Ù„Ù…Ø§Ø¯Ø©', y='Ø§Ù„ØªÙ‚Ø¯ÙŠØ±', color='Ø§Ù„Ù…Ø§Ø¯Ø©')
                    fig_box.update_layout(height=500, width=1100, showlegend=False)
                    
                    img_stream = fig_to_image(fig_box)
                    if img_stream:
                        slide.shapes.add_picture(img_stream, Inches(1), Inches(1.3), width=Inches(11))
                
                # Top 10 Students
                slide = add_content_slide(prs, "ğŸ† Ø£ÙØ¶Ù„ 10 ØªÙ„Ø§Ù…ÙŠØ°")
                
                top_10 = data_df[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']].dropna().nlargest(10, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')
                
                rows = len(top_10) + 1
                cols = 3
                table = slide.shapes.add_table(rows, cols, Inches(2), Inches(1.3), Inches(9), Inches(5)).table
                
                table.cell(0, 0).text = "Ø§Ù„ØªØ±ØªÙŠØ¨"
                table.cell(0, 1).text = "Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°"
                table.cell(0, 2).text = "Ø§Ù„Ù…Ø¹Ø¯Ù„"
                
                for i, (idx, row) in enumerate(top_10.iterrows()):
                    table.cell(i+1, 0).text = str(i+1)
                    table.cell(i+1, 1).text = str(row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°'])
                    table.cell(i+1, 2).text = f"{row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}"
                
                for i in range(rows):
                    for j in range(cols):
                        cell = table.cell(i, j)
                        cell.text_frame.paragraphs[0].font.size = Pt(14)
                        cell.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER
                
                # Subject Insights
                slide = add_content_slide(prs, "ğŸ’¡ Ø£Ù‡Ù… Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª")
                
                best_subject = stats_df_ppt.loc[stats_df_ppt['Ø§Ù„Ù…ØªÙˆØ³Ø·'].idxmax()]
                worst_subject = stats_df_ppt.loc[stats_df_ppt['Ø§Ù„Ù…ØªÙˆØ³Ø·'].idxmin()]
                most_consistent = stats_df_ppt.loc[stats_df_ppt['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ'].idxmin()]
                most_varied = stats_df_ppt.loc[stats_df_ppt['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ'].idxmax()]
                
                insights_text = f"""
âœ… Ø£ÙØ¶Ù„ Ù…Ø§Ø¯Ø© Ø£Ø¯Ø§Ø¡Ù‹: {best_subject['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ù…ØªÙˆØ³Ø·: {best_subject['Ø§Ù„Ù…ØªÙˆØ³Ø·']:.2f})

âš ï¸ Ù…Ø§Ø¯Ø© ØªØ­ØªØ§Ø¬ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Ù‹: {worst_subject['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ù…ØªÙˆØ³Ø·: {worst_subject['Ø§Ù„Ù…ØªÙˆØ³Ø·']:.2f})

ğŸ“Š Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹: {most_consistent['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {most_consistent['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ']:.2f})

ğŸ“ˆ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø£ÙƒØ«Ø± ØªØ¨Ø§ÙŠÙ†Ø§Ù‹: {most_varied['Ø§Ù„Ù…Ø§Ø¯Ø©']} (Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ: {most_varied['Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ']:.2f})

ğŸ¯ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {(avg_count + good_count)/total*100:.1f}%

ğŸŒŸ Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ…ÙŠØ² (â‰¥12): {good_count/total*100:.1f}%
                """
                
                insights_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.5), Inches(12), Inches(5))
                insights_frame = insights_box.text_frame
                insights_frame.word_wrap = True
                for line in insights_text.strip().split('\n'):
                    p = insights_frame.add_paragraph()
                    p.text = line.strip()
                    p.font.size = Pt(24)
                    p.space_after = Pt(12)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # ====== NEW SECTIONS ======
                
                # Top & Bottom Performers Slide
                slide = add_content_slide(prs, "ğŸ† Ø£ÙØ¶Ù„ ÙˆØ£Ø¶Ø¹Ù Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°")
                
                top_5 = data_df[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']].dropna().nlargest(5, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')
                bottom_5 = data_df[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']].dropna().nsmallest(5, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')
                
                # RTL: Top performers on the RIGHT
                top_text = "ğŸ¥‡ Ø£ÙØ¶Ù„ 5 ØªÙ„Ø§Ù…ÙŠØ°:\n"
                rank_emojis = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰', '4ï¸âƒ£', '5ï¸âƒ£']
                for i, (idx, row) in enumerate(top_5.iterrows()):
                    top_text += f"{rank_emojis[i]} {row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']}: {row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}\n"
                
                top_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(3))
                top_frame = top_box.text_frame
                top_frame.word_wrap = True
                for line in top_text.strip().split('\n'):
                    p = top_frame.add_paragraph()
                    p.text = line
                    p.font.size = Pt(20)
                    p.space_after = Pt(6)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # RTL: Bottom performers on the LEFT
                bottom_text = "ğŸ“‰ ØªÙ„Ø§Ù…ÙŠØ° ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹:\n"
                for i, (idx, row) in enumerate(bottom_5.iterrows()):
                    bottom_text += f"â€¢ {row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']}: {row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}\n"
                
                bottom_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.3), Inches(6), Inches(3))
                bottom_frame = bottom_box.text_frame
                bottom_frame.word_wrap = True
                for line in bottom_text.strip().split('\n'):
                    p = bottom_frame.add_paragraph()
                    p.text = line
                    p.font.size = Pt(20)
                    p.space_after = Pt(6)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # Science vs Humanities Slide
                slide = add_content_slide(prs, "ğŸ”¬ğŸ“š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„Ø¢Ø¯Ø§Ø¨")
                
                science_subjects_ppt = ['Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª', 'Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­ÙŠØ§Ø© ÙˆØ§Ù„Ø£Ø±Ø¶', 'Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ ÙˆØ§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡']
                humanities_subjects_ppt = ['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©', 'Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ§Øª']
                
                science_scores_ppt = []
                humanities_scores_ppt = []
                
                for col in science_subjects_ppt:
                    if col in data_df.columns:
                        science_scores_ppt.extend(data_df[col].dropna().tolist())
                
                for col in humanities_subjects_ppt:
                    if col in data_df.columns:
                        humanities_scores_ppt.extend(data_df[col].dropna().tolist())
                
                science_avg_ppt = np.mean(science_scores_ppt) if science_scores_ppt else 0
                humanities_avg_ppt = np.mean(humanities_scores_ppt) if humanities_scores_ppt else 0
                diff_ppt = science_avg_ppt - humanities_avg_ppt
                
                if diff_ppt > 0.5:
                    orientation = "ØªÙˆØ¬Ù‡ Ø¹Ù„Ù…ÙŠ"
                elif diff_ppt < -0.5:
                    orientation = "ØªÙˆØ¬Ù‡ Ø£Ø¯Ø¨ÙŠ"
                else:
                    orientation = "Ù…ØªÙˆØ§Ø²Ù†"
                
                sci_hum_text = f"""
ğŸ”¬ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©: {science_avg_ppt:.2f}
(Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§ØªØŒ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­ÙŠØ§Ø© ÙˆØ§Ù„Ø£Ø±Ø¶ØŒ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ ÙˆØ§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡)

ğŸ“š Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©: {humanities_avg_ppt:.2f}
(Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©ØŒ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ§Øª)

ğŸ“Š Ø§Ù„ÙØ±Ù‚: {diff_ppt:.2f} Ù†Ù‚Ø·Ø©

ğŸ¯ Ø§Ù„ØªÙˆØ¬Ù‡ Ø§Ù„Ø¹Ø§Ù…: {orientation}
                """
                
                # RTL: Text on the right
                sci_hum_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(5))
                sci_hum_frame = sci_hum_box.text_frame
                sci_hum_frame.word_wrap = True
                for line in sci_hum_text.strip().split('\n'):
                    p = sci_hum_frame.add_paragraph()
                    p.text = line
                    p.font.size = Pt(22)
                    p.space_after = Pt(8)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # Science vs Humanities bar chart
                comparison_df_ppt = pd.DataFrame({
                    'Ø§Ù„Ù…Ø¬Ø§Ù„': ['Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©', 'Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©'],
                    'Ø§Ù„Ù…ØªÙˆØ³Ø·': [science_avg_ppt, humanities_avg_ppt]
                })
                
                fig_comparison = px.bar(
                    comparison_df_ppt,
                    x='Ø§Ù„Ù…Ø¬Ø§Ù„',
                    y='Ø§Ù„Ù…ØªÙˆØ³Ø·',
                    color='Ø§Ù„Ù…Ø¬Ø§Ù„',
                    color_discrete_map={
                        'Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©': '#636EFA',
                        'Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ø£Ø¯Ø¨ÙŠØ©': '#EF553B'
                    },
                    text='Ø§Ù„Ù…ØªÙˆØ³Ø·'
                )
                fig_comparison.update_traces(texttemplate='%{text:.2f}', textposition='outside')
                fig_comparison.update_layout(height=400, width=500, showlegend=False)
                fig_comparison.add_hline(y=10, line_dash="dash", line_color="green")
                
                img_stream = fig_to_image(fig_comparison)
                if img_stream:
                    # RTL: Chart on the left
                    slide.shapes.add_picture(img_stream, Inches(0.5), Inches(1.3), width=Inches(6))
                
                # ====== ENRICHMENT SUBJECTS SLIDE ======
                slide = add_content_slide(prs, "ğŸ¨ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­ (Ø§Ù„Ø£Ù†Ø´Ø·Ø©)")
                
                enrichment_subjects_ppt = ['Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©', 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¨Ø¯Ù†ÙŠØ©', 'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…ÙŠØ§Øª', 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„ØªØ´ÙƒÙŠÙ„ÙŠØ©']
                enrichment_data_ppt = []
                
                for subj in enrichment_subjects_ppt:
                    if subj in data_df.columns:
                        avg_val = data_df[subj].dropna().mean()
                        pass_rate = (data_df[subj].dropna() >= 10).mean() * 100
                        enrichment_data_ppt.append({
                            'Ø§Ù„Ù…Ø§Ø¯Ø©': subj,
                            'Ø§Ù„Ù…ØªÙˆØ³Ø·': avg_val,
                            'Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­': pass_rate
                        })
                
                if enrichment_data_ppt:
                    enrichment_df_ppt = pd.DataFrame(enrichment_data_ppt)
                    
                    # Enrichment text
                    enrichment_text = "ğŸ“Š Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙÙŠ Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙØªØ­:\n\n"
                    for _, row in enrichment_df_ppt.iterrows():
                        emoji = "âœ…" if row['Ø§Ù„Ù…ØªÙˆØ³Ø·'] >= 10 else "âš ï¸"
                        enrichment_text += f"{emoji} {row['Ø§Ù„Ù…Ø§Ø¯Ø©']}: {row['Ø§Ù„Ù…ØªÙˆØ³Ø·']:.2f} (Ù†Ø¬Ø§Ø­: {row['Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­']:.0f}%)\n"
                    
                    # RTL: Text on the right
                    enr_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(5))
                    enr_frame = enr_box.text_frame
                    enr_frame.word_wrap = True
                    for line in enrichment_text.strip().split('\n'):
                        p = enr_frame.add_paragraph()
                        p.text = line
                        p.font.size = Pt(20)
                        p.space_after = Pt(6)
                        p.alignment = PP_ALIGN.RIGHT
                        set_paragraph_rtl(p)
                    
                    # Enrichment bar chart
                    fig_enr = px.bar(
                        enrichment_df_ppt,
                        x='Ø§Ù„Ù…Ø§Ø¯Ø©',
                        y='Ø§Ù„Ù…ØªÙˆØ³Ø·',
                        color='Ø§Ù„Ù…ØªÙˆØ³Ø·',
                        color_continuous_scale='RdYlGn',
                        text='Ø§Ù„Ù…ØªÙˆØ³Ø·'
                    )
                    fig_enr.update_traces(texttemplate='%{text:.2f}', textposition='outside')
                    fig_enr.update_layout(height=400, width=500, showlegend=False)
                    fig_enr.add_hline(y=10, line_dash="dash", line_color="green")
                    
                    img_stream = fig_to_image(fig_enr)
                    if img_stream:
                        slide.shapes.add_picture(img_stream, Inches(0.5), Inches(1.3), width=Inches(6))
                
                # Language Proficiency Gap Slide
                slide = add_content_slide(prs, "ğŸŒ ÙØ¬ÙˆØ© Ø§Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù„ØºÙˆÙŠØ©")
                
                arabic_avg_ppt = data_df['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©'].dropna().mean() if 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' in data_df.columns else 0
                french_avg_ppt = data_df['Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©'].dropna().mean() if 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©' in data_df.columns else 0
                english_avg_ppt = data_df['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'].dropna().mean() if 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©' in data_df.columns else 0
                foreign_avg_ppt = np.mean([french_avg_ppt, english_avg_ppt]) if (french_avg_ppt > 0 or english_avg_ppt > 0) else 0
                proficiency_gap_ppt = arabic_avg_ppt - foreign_avg_ppt
                
                lang_text = f"""
ğŸ‡²ğŸ‡¦ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ù…): {arabic_avg_ppt:.2f}

ğŸ‡«ğŸ‡· Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©: {french_avg_ppt:.2f}

ğŸ‡¬ğŸ‡§ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©: {english_avg_ppt:.2f}

ğŸ“Š ÙØ¬ÙˆØ© Ø§Ù„ÙƒÙØ§Ø¡Ø© (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©): {proficiency_gap_ppt:.2f}
                """
                
                if proficiency_gap_ppt > 2:
                    lang_text += "\n\nâš ï¸ ÙØ¬ÙˆØ© ÙƒØ¨ÙŠØ±Ø©: Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠÙˆØ§Ø¬Ù‡ÙˆÙ† ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©"
                elif proficiency_gap_ppt > 1:
                    lang_text += "\n\nğŸ“Š ÙØ¬ÙˆØ© Ù…ØªÙˆØ³Ø·Ø©: ÙŠØ­ØªØ§Ø¬ ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©"
                else:
                    lang_text += "\n\nâœ… ÙØ¬ÙˆØ© ØµØºÙŠØ±Ø©: Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…ØªÙ‚Ø§Ø±Ø¨ Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª"
                
                # RTL: Text on the right
                lang_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(5))
                lang_frame = lang_box.text_frame
                lang_frame.word_wrap = True
                for line in lang_text.strip().split('\n'):
                    p = lang_frame.add_paragraph()
                    p.text = line
                    p.font.size = Pt(22)
                    p.space_after = Pt(8)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # Language comparison bar chart
                lang_df_ppt = pd.DataFrame({
                    'Ø§Ù„Ù„ØºØ©': ['Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'],
                    'Ø§Ù„Ù…ØªÙˆØ³Ø·': [arabic_avg_ppt, french_avg_ppt, english_avg_ppt],
                    'Ø§Ù„Ù†ÙˆØ¹': ['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ù…', 'Ù„ØºØ© Ø£Ø¬Ù†Ø¨ÙŠØ©', 'Ù„ØºØ© Ø£Ø¬Ù†Ø¨ÙŠØ©']
                })
                
                fig_lang = px.bar(
                    lang_df_ppt,
                    x='Ø§Ù„Ù„ØºØ©',
                    y='Ø§Ù„Ù…ØªÙˆØ³Ø·',
                    color='Ø§Ù„Ù†ÙˆØ¹',
                    color_discrete_map={
                        'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø£Ù…': '#00CC96',
                        'Ù„ØºØ© Ø£Ø¬Ù†Ø¨ÙŠØ©': '#EF553B'
                    },
                    text='Ø§Ù„Ù…ØªÙˆØ³Ø·'
                )
                fig_lang.update_traces(texttemplate='%{text:.2f}', textposition='outside')
                fig_lang.update_layout(height=400, width=500, showlegend=True)
                fig_lang.add_hline(y=10, line_dash="dash", line_color="gray")
                
                img_stream = fig_to_image(fig_lang)
                if img_stream:
                    # RTL: Chart on the left
                    slide.shapes.add_picture(img_stream, Inches(0.5), Inches(1.3), width=Inches(6))
                
                # ====== LANGUAGE SUCCESS RATES SLIDE ======
                slide = add_content_slide(prs, "ğŸ“Š Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ù„ØºØ§Øª")
                
                # Calculate success rates
                ar_pass_ppt = 0
                fr_pass_ppt = 0
                en_pass_ppt = 0
                
                if 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©' in data_df.columns:
                    ar_pass_ppt = (data_df['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©'].dropna() >= 10).mean() * 100
                if 'Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©' in data_df.columns:
                    fr_pass_ppt = (data_df['Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©'].dropna() >= 10).mean() * 100
                if 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©' in data_df.columns:
                    en_pass_ppt = (data_df['Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'].dropna() >= 10).mean() * 100
                
                # Create success rates bar chart
                pass_df_ppt = pd.DataFrame({
                    'Ø§Ù„Ù„ØºØ©': ['Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', 'Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'],
                    'Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %': [ar_pass_ppt, fr_pass_ppt, en_pass_ppt]
                })
                
                fig_pass = px.bar(
                    pass_df_ppt,
                    x='Ø§Ù„Ù„ØºØ©',
                    y='Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %',
                    color='Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %',
                    color_continuous_scale='RdYlGn',
                    text='Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ %'
                )
                fig_pass.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
                fig_pass.update_layout(height=400, width=500, title="Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ ÙƒÙ„ Ù„ØºØ© (â‰¥10)")
                
                img_stream_pass = fig_to_image(fig_pass)
                if img_stream_pass:
                    slide.shapes.add_picture(img_stream_pass, Inches(0.5), Inches(1.3), width=Inches(6))
                
                # Analysis text for success rates
                success_analysis = f"""ğŸ“ˆ Ù†Ø³Ø¨ Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ù„ØºØ§Øª:

ğŸ‡²ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: {ar_pass_ppt:.1f}%
ğŸ‡«ğŸ‡· Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©: {fr_pass_ppt:.1f}%
ğŸ‡¬ğŸ‡§ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©: {en_pass_ppt:.1f}%

"""
                # Add insights
                struggling_langs_ppt = []
                if fr_pass_ppt < 50:
                    struggling_langs_ppt.append("Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©")
                if en_pass_ppt < 50:
                    struggling_langs_ppt.append("Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")
                
                if struggling_langs_ppt:
                    success_analysis += f"âš ï¸ Ù„ØºØ§Øª ØªØ­ØªØ§Ø¬ Ø¯Ø¹Ù…: {', '.join(struggling_langs_ppt)}"
                else:
                    success_analysis += "âœ… Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù„ØºØ§Øª"
                
                success_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(5))
                success_frame = success_box.text_frame
                success_frame.word_wrap = True
                for line in success_analysis.strip().split('\n'):
                    p = success_frame.add_paragraph()
                    p.text = line
                    p.font.size = Pt(24)
                    p.space_after = Pt(10)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # ====== LANGUAGE GAP DISTRIBUTION SLIDE ======
                slide = add_content_slide(prs, "ğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ©")
                
                # Calculate student-level language gaps
                student_gap_ppt = []
                for idx, row in data_df.iterrows():
                    arabic_score = row.get('Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©', np.nan)
                    foreign_scores = [row.get(col, np.nan) for col in ['Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©', 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'] if col in data_df.columns]
                    foreign_scores = [s for s in foreign_scores if pd.notna(s)]
                    
                    if pd.notna(arabic_score) and foreign_scores:
                        avg_foreign = sum(foreign_scores) / len(foreign_scores)
                        gap = arabic_score - avg_foreign
                        student_gap_ppt.append(gap)
                
                if student_gap_ppt:
                    valid_gaps_ppt = [g for g in student_gap_ppt if pd.notna(g)]
                    if valid_gaps_ppt:
                        # Statistics
                        positive_gap_ppt = sum(1 for g in valid_gaps_ppt if g > 1)
                        negative_gap_ppt = sum(1 for g in valid_gaps_ppt if g < -1)
                        balanced_ppt = len(valid_gaps_ppt) - positive_gap_ppt - negative_gap_ppt
                        
                        gap_df_ppt = pd.DataFrame({'Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ©': valid_gaps_ppt})
                        fig_gap_hist = px.histogram(
                            gap_df_ppt,
                            x='Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ©',
                            nbins=20,
                            color_discrete_sequence=['#636EFA']
                        )
                        fig_gap_hist.add_vline(x=0, line_dash="dash", line_color="red", annotation_text="ØªÙˆØ§Ø²Ù†")
                        fig_gap_hist.update_layout(
                            title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ©",
                            height=400, width=550
                        )
                        
                        img_stream_gap = fig_to_image(fig_gap_hist)
                        if img_stream_gap:
                            slide.shapes.add_picture(img_stream_gap, Inches(0.3), Inches(1.3), width=Inches(6.2))
                        
                        gap_analysis = f"""ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„Ù„ØºÙˆÙŠØ©:

ğŸ“ˆ Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©: {positive_gap_ppt} ØªÙ„Ù…ÙŠØ° ({positive_gap_ppt/len(valid_gaps_ppt)*100:.1f}%)
âš–ï¸ Ù…ØªÙˆØ§Ø²Ù†: {balanced_ppt} ØªÙ„Ù…ÙŠØ° ({balanced_ppt/len(valid_gaps_ppt)*100:.1f}%)
ğŸŒ Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©: {negative_gap_ppt} ØªÙ„Ù…ÙŠØ° ({negative_gap_ppt/len(valid_gaps_ppt)*100:.1f}%)

"""
                        avg_gap_ppt = sum(valid_gaps_ppt) / len(valid_gaps_ppt)
                        if avg_gap_ppt > 1:
                            gap_analysis += "âš ï¸ ØºØ§Ù„Ø¨ÙŠØ© Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹ ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©"
                        elif avg_gap_ppt < -1:
                            gap_analysis += "ğŸŒŸ ØºØ§Ù„Ø¨ÙŠØ© Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ù…ØªÙÙˆÙ‚ÙˆÙ† ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ©"
                        else:
                            gap_analysis += "âœ… ØªÙˆØ²ÙŠØ¹ Ù…ØªÙˆØ§Ø²Ù† Ù„Ù„ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù„ØºÙˆÙŠØ©"
                        
                        gap_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(5))
                        gap_frame = gap_box.text_frame
                        gap_frame.word_wrap = True
                        for line in gap_analysis.strip().split('\n'):
                            p = gap_frame.add_paragraph()
                            p.text = line
                            p.font.size = Pt(22)
                            p.space_after = Pt(8)
                            p.alignment = PP_ALIGN.RIGHT
                            set_paragraph_rtl(p)
                
                # Correlation Analysis Slide
                slide = add_content_slide(prs, "ğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯")
                
                correlation_subjects_ppt = [col for col in subject_columns if col in data_df.columns and col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„']
                correlation_data_ppt = data_df[correlation_subjects_ppt].dropna()
                
                if len(correlation_data_ppt) > 5 and len(correlation_subjects_ppt) > 1:
                    corr_matrix_ppt = correlation_data_ppt.corr()
                    
                    # Find strongest correlations
                    correlations_ppt = []
                    for i in range(len(correlation_subjects_ppt)):
                        for j in range(i + 1, len(correlation_subjects_ppt)):
                            correlations_ppt.append({
                                'Ø§Ù„Ù…Ø§Ø¯Ø© 1': correlation_subjects_ppt[i],
                                'Ø§Ù„Ù…Ø§Ø¯Ø© 2': correlation_subjects_ppt[j],
                                'Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·': corr_matrix_ppt.iloc[i, j]
                            })
                    
                    corr_df_ppt = pd.DataFrame(correlations_ppt)
                    corr_df_ppt = corr_df_ppt.sort_values('Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·', ascending=False, key=abs)
                    
                    avg_corr = corr_df_ppt['Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·'].mean()
                    strongest = corr_df_ppt.iloc[0] if len(corr_df_ppt) > 0 else None
                    weakest = corr_df_ppt.iloc[-1] if len(corr_df_ppt) > 0 else None
                    
                    corr_text = f"""
ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¯: {avg_corr:.2f}

ğŸ”— Ø£Ù‚ÙˆÙ‰ Ø§Ø±ØªØ¨Ø§Ø·:
{strongest['Ø§Ù„Ù…Ø§Ø¯Ø© 1']} â†” {strongest['Ø§Ù„Ù…Ø§Ø¯Ø© 2']}: {strongest['Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·']:.2f}

â›“ï¸ Ø£Ø¶Ø¹Ù Ø§Ø±ØªØ¨Ø§Ø·:
{weakest['Ø§Ù„Ù…Ø§Ø¯Ø© 1']} â†” {weakest['Ø§Ù„Ù…Ø§Ø¯Ø© 2']}: {weakest['Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·']:.2f}
                    """
                    
                    if avg_corr >= 0.5:
                        corr_text += "\n\nğŸ¯ ØªØ±Ø§Ø¨Ø· Ø¹Ø§Ù… Ù‚ÙˆÙŠ: Ø§Ù„Ù…ØªÙÙˆÙ‚ÙˆÙ† ÙŠØªÙÙˆÙ‚ÙˆÙ† ÙÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…ÙˆØ§Ø¯"
                    elif avg_corr >= 0.3:
                        corr_text += "\n\nğŸ“Š ØªØ±Ø§Ø¨Ø· Ù…ØªÙˆØ³Ø·: Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙˆØ§Ø¯ Ù…ØªØ±Ø§Ø¨Ø·Ø©"
                    else:
                        corr_text += "\n\nâš ï¸ ØªØ±Ø§Ø¨Ø· Ø¶Ø¹ÙŠÙ: ÙƒÙ„ Ù…Ø§Ø¯Ø© ØªØªØ·Ù„Ø¨ Ù…Ù‡Ø§Ø±Ø§Øª Ù…Ø®ØªÙ„ÙØ©"
                    
                    # RTL: Text on the right
                    corr_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(5))
                    corr_frame = corr_box.text_frame
                    corr_frame.word_wrap = True
                    for line in corr_text.strip().split('\n'):
                        p = corr_frame.add_paragraph()
                        p.text = line
                        p.font.size = Pt(20)
                        p.space_after = Pt(6)
                        p.alignment = PP_ALIGN.RIGHT
                        set_paragraph_rtl(p)
                    
                    # Correlation heatmap - on the left
                    fig_corr = px.imshow(
                        corr_matrix_ppt,
                        labels=dict(x="Ø§Ù„Ù…Ø§Ø¯Ø©", y="Ø§Ù„Ù…Ø§Ø¯Ø©", color="Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·"),
                        x=correlation_subjects_ppt,
                        y=correlation_subjects_ppt,
                        color_continuous_scale='RdBu_r',
                        zmin=-1,
                        zmax=1
                    )
                    fig_corr.update_layout(height=450, width=500)
                    
                    img_stream = fig_to_image(fig_corr)
                    if img_stream:
                        # RTL: Chart on the left
                        slide.shapes.add_picture(img_stream, Inches(0.5), Inches(1.2), width=Inches(6))
                
                # At-Risk Students Slide
                slide = add_content_slide(prs, "ğŸš¨ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ù…Ø¹Ø±Ø¶ÙŠÙ† Ù„Ù„Ø®Ø·Ø±")
                
                avg_mean_ppt = data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].dropna().mean()
                avg_std_ppt = data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].dropna().std()
                
                at_risk_ppt = data_df[data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 9]
                borderline_ppt = data_df[(data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= 9) & (data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] < 10)]
                excellent_ppt = data_df[data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'] >= avg_mean_ppt + 1.5 * avg_std_ppt]
                
                risk_text = f"""
ğŸ”´ Ù…Ø¹Ø±Ø¶ÙˆÙ† Ù„Ù„Ø®Ø·Ø± (Ù…Ø¹Ø¯Ù„ < 9): {len(at_risk_ppt)} ØªÙ„Ø§Ù…ÙŠØ°
ÙŠØ­ØªØ§Ø¬ÙˆÙ† ØªØ¯Ø®Ù„Ø§Ù‹ Ø¹Ø§Ø¬Ù„Ø§Ù‹

ğŸŸ¡ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§ÙØ© (Ù…Ø¹Ø¯Ù„ 9-10): {len(borderline_ppt)} ØªÙ„Ø§Ù…ÙŠØ°
Ù‚Ø±ÙŠØ¨ÙˆÙ† Ù…Ù† Ø§Ù„Ø±Ø³ÙˆØ¨

â­ Ù…ØªÙ…ÙŠØ²ÙˆÙ†: {len(excellent_ppt)} ØªÙ„Ø§Ù…ÙŠØ°
ÙŠÙ…ÙƒÙ† Ø¥Ø´Ø±Ø§ÙƒÙ‡Ù… ÙÙŠ Ù…Ø³Ø§Ø¹Ø¯Ø© Ø²Ù…Ù„Ø§Ø¦Ù‡Ù…
                """
                
                # RTL: Risk text on the right
                risk_box = slide.shapes.add_textbox(Inches(6.5), Inches(1.3), Inches(6.3), Inches(4))
                risk_frame = risk_box.text_frame
                risk_frame.word_wrap = True
                for line in risk_text.strip().split('\n'):
                    p = risk_frame.add_paragraph()
                    p.text = line
                    p.font.size = Pt(22)
                    p.space_after = Pt(8)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # At-risk students list - on the left
                if len(at_risk_ppt) > 0:
                    at_risk_names = at_risk_ppt.nsmallest(5, 'Ø§Ù„Ù…Ø¹Ø¯Ù„')[['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°', 'Ø§Ù„Ù…Ø¹Ø¯Ù„']]
                    at_risk_list = "ğŸ“‹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ° Ø§Ù„Ø£ÙƒØ«Ø± Ø®Ø·Ø±Ø§Ù‹:\n"
                    for idx, row in at_risk_names.iterrows():
                        at_risk_list += f"â€¢ {row['Ø§Ø³Ù… Ø§Ù„ØªÙ„Ù…ÙŠØ°']}: {row['Ø§Ù„Ù…Ø¹Ø¯Ù„']:.2f}\n"
                    
                    at_risk_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.3), Inches(6), Inches(4))
                    at_risk_frame = at_risk_box.text_frame
                    at_risk_frame.word_wrap = True
                    for line in at_risk_list.strip().split('\n'):
                        p = at_risk_frame.add_paragraph()
                        p.text = line
                        p.font.size = Pt(20)
                        p.space_after = Pt(6)
                        p.alignment = PP_ALIGN.RIGHT
                        set_paragraph_rtl(p)
                
                # Subject Failure Analysis Slide
                slide = add_content_slide(prs, "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù†Ø³Ø¨ Ø§Ù„Ø±Ø³ÙˆØ¨ ÙÙŠ Ø§Ù„Ù…ÙˆØ§Ø¯")
                
                subject_failure_ppt = []
                for col in subject_columns:
                    if col != 'Ø§Ù„Ù…Ø¹Ø¯Ù„' and col in data_df.columns:
                        subject_data_ppt = data_df[col].dropna()
                        if len(subject_data_ppt) > 0:
                            failing_pct = (subject_data_ppt < 10).mean() * 100
                            subject_failure_ppt.append({
                                'Ø§Ù„Ù…Ø§Ø¯Ø©': col,
                                'Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨': failing_pct
                            })
                
                if subject_failure_ppt:
                    failure_df_ppt = pd.DataFrame(subject_failure_ppt)
                    failure_df_ppt = failure_df_ppt.sort_values('Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨', ascending=False)
                    
                    fig_failure = px.bar(
                        failure_df_ppt,
                        x='Ø§Ù„Ù…Ø§Ø¯Ø©',
                        y='Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨',
                        color='Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨',
                        color_continuous_scale='RdYlGn_r',
                        text='Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨'
                    )
                    fig_failure.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
                    fig_failure.update_layout(height=450, width=1000)
                    fig_failure.add_hline(y=50, line_dash="dash", line_color="red", annotation_text="Ø®Ø· Ø§Ù„Ø®Ø·Ø±")
                    
                    img_stream = fig_to_image(fig_failure)
                    if img_stream:
                        slide.shapes.add_picture(img_stream, Inches(1.5), Inches(1.3), width=Inches(10))
                    
                    # Critical subjects warning
                    critical = failure_df_ppt[failure_df_ppt['Ù†Ø³Ø¨Ø© Ø§Ù„Ø±Ø³ÙˆØ¨'] > 50]
                    if len(critical) > 0:
                        critical_text = f"âš ï¸ Ù…ÙˆØ§Ø¯ Ø­Ø±Ø¬Ø© (> 50% Ø±Ø³ÙˆØ¨): {', '.join(critical['Ø§Ù„Ù…Ø§Ø¯Ø©'].tolist())}"
                        critical_box = slide.shapes.add_textbox(Inches(0.5), Inches(6), Inches(12), Inches(1))
                        critical_frame = critical_box.text_frame
                        p = critical_frame.paragraphs[0]
                        p.text = critical_text
                        p.font.size = Pt(20)
                        p.font.bold = True
                
                # Final Recommendations Slide
                slide = add_content_slide(prs, "ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª ÙˆØ§Ù„Ø®Ù„Ø§ØµØ©")
                
                recommendations_text = """
ğŸ“Œ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:

"""
                
                if len(at_risk_ppt) > 0:
                    recommendations_text += f"ğŸ”´ ØªØ¯Ø®Ù„ Ø¹Ø§Ø¬Ù„: {len(at_risk_ppt)} ØªÙ„Ø§Ù…ÙŠØ° ÙŠØ­ØªØ§Ø¬ÙˆÙ† Ø¯Ø¹Ù…Ø§Ù‹ Ù…ÙƒØ«ÙØ§Ù‹\n\n"
                
                if len(borderline_ppt) > 0:
                    recommendations_text += f"ğŸŸ¡ Ù…ØªØ§Ø¨Ø¹Ø© Ø¯Ù‚ÙŠÙ‚Ø©: {len(borderline_ppt)} ØªÙ„Ø§Ù…ÙŠØ° Ø¹Ù„Ù‰ Ø­Ø§ÙØ© Ø§Ù„Ø±Ø³ÙˆØ¨\n\n"
                
                if worst_subject['Ø§Ù„Ù…ØªÙˆØ³Ø·'] < 10:
                    recommendations_text += f"ğŸ“š Ù…Ø±Ø§Ø¬Ø¹Ø© Ø·Ø±Ù‚ Ø§Ù„ØªØ¯Ø±ÙŠØ³: {worst_subject['Ø§Ù„Ù…Ø§Ø¯Ø©']} ØªØ­ØªØ§Ø¬ Ø§Ù‡ØªÙ…Ø§Ù…Ø§Ù‹ Ø®Ø§ØµØ§Ù‹\n\n"
                
                if len(excellent_ppt) > 0:
                    recommendations_text += f"â­ Ø¨Ø±Ù†Ø§Ù…Ø¬ ØªÙ…ÙŠØ²: Ø¥Ø´Ø±Ø§Ùƒ {len(excellent_ppt)} ØªÙ„Ø§Ù…ÙŠØ° Ù…ØªÙ…ÙŠØ²ÙŠÙ† ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©\n\n"
                
                recommendations_text += f"""
ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡:
â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {(avg_count + good_count)/total*100:.1f}%
â€¢ Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙ…ÙŠØ²: {good_count/total*100:.1f}%
â€¢ Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹Ø§Ù…: {data_df['Ø§Ù„Ù…Ø¹Ø¯Ù„'].mean():.2f}
                """
                
                rec_box = slide.shapes.add_textbox(Inches(0.5), Inches(1.4), Inches(12), Inches(5.5))
                rec_frame = rec_box.text_frame
                rec_frame.word_wrap = True
                for line in recommendations_text.strip().split('\n'):
                    p = rec_frame.add_paragraph()
                    p.text = line
                    p.font.size = Pt(22)
                    p.space_after = Pt(8)
                    p.alignment = PP_ALIGN.RIGHT
                    set_paragraph_rtl(p)
                
                # Fancy Thank You slide
                slide_layout = prs.slide_layouts[6]  # Blank layout
                slide = prs.slides.add_slide(slide_layout)
                
                # Add gradient background (green to blue)
                add_gradient_background(slide, RGBColor(0, 100, 80), RGBColor(25, 55, 95))
                
                # Add decorative elements
                add_decorative_shape(slide, MSO_SHAPE.OVAL, Inches(-1), Inches(-1), Inches(4), Inches(4), 
                                    RGBColor(255, 255, 255), 0.92)
                add_decorative_shape(slide, MSO_SHAPE.OVAL, Inches(11), Inches(5), Inches(3), Inches(3), 
                                    RGBColor(255, 255, 255), 0.93)
                add_decorative_shape(slide, MSO_SHAPE.OVAL, Inches(5), Inches(5.5), Inches(2), Inches(2), 
                                    RGBColor(255, 192, 0), 0.85)
                
                # Thank you emoji
                emoji_box = slide.shapes.add_textbox(Inches(5.5), Inches(1.5), Inches(2.333), Inches(1.5))
                emoji_frame = emoji_box.text_frame
                emoji_para = emoji_frame.paragraphs[0]
                emoji_para.text = "ğŸ‰"
                emoji_para.font.size = Pt(72)
                emoji_para.alignment = PP_ALIGN.CENTER
                
                # Main thank you text
                thanks_box = slide.shapes.add_textbox(Inches(0.5), Inches(3), Inches(12.333), Inches(1.2))
                thanks_frame = thanks_box.text_frame
                thanks_para = thanks_frame.paragraphs[0]
                thanks_para.text = "Ø´ÙƒØ±Ø§Ù‹ Ù„ÙƒÙ…!"
                thanks_para.font.size = Pt(60)
                thanks_para.font.bold = True
                thanks_para.font.color.rgb = RGBColor(255, 255, 255)
                thanks_para.alignment = PP_ALIGN.CENTER
                set_paragraph_rtl(thanks_para)
                
                # Subtitle
                sub_box = slide.shapes.add_textbox(Inches(0.5), Inches(4.3), Inches(12.333), Inches(0.8))
                sub_frame = sub_box.text_frame
                sub_para = sub_frame.paragraphs[0]
                sub_para.text = "ØªÙ… Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù† Ù„ÙˆØ­Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙ„Ø§Ù…ÙŠØ°"
                sub_para.font.size = Pt(24)
                sub_para.font.color.rgb = RGBColor(200, 230, 220)
                sub_para.alignment = PP_ALIGN.CENTER
                set_paragraph_rtl(sub_para)
                
                # Add decorative line
                line_shape = slide.shapes.add_shape(MSO_SHAPE.RECTANGLE, Inches(4), Inches(5.3), 
                                                     Inches(5.333), Inches(0.06))
                line_shape.fill.solid()
                line_shape.fill.fore_color.rgb = ACCENT_COLOR
                line_shape.line.fill.background()
                
                # Footer with date
                from datetime import datetime
                footer_box = slide.shapes.add_textbox(Inches(0.5), Inches(6.5), Inches(12.333), Inches(0.5))
                footer_frame = footer_box.text_frame
                footer_para = footer_frame.paragraphs[0]
                footer_para.text = f"ğŸ“… {datetime.now().strftime('%Y-%m-%d')}"
                footer_para.font.size = Pt(14)
                footer_para.font.color.rgb = RGBColor(180, 200, 190)
                footer_para.alignment = PP_ALIGN.CENTER
                set_paragraph_rtl(footer_para)
            
            # Generate presentation based on combine option
            if combine_all_classes:
                # Combined presentation for all selected classes
                generate_slides_for_data(prs, df_ppt, "", selected_classes_ppt)
            else:
                # Separate sections for each class
                for i, class_name in enumerate(selected_classes_ppt):
                    class_df = df_ppt[df_ppt['Ø§Ù„ÙØµÙ„'] == class_name].copy()
                    if len(class_df) > 0:
                        if i > 0:
                            # Add separator slide between classes
                            add_title_slide(prs, f"ğŸ“š {class_name}", f"Ø§Ù„ÙØµÙ„ {i+1} Ù…Ù† {len(selected_classes_ppt)}")
                        generate_slides_for_data(prs, class_df, f"- {class_name}", [class_name])
            
            # Save presentation
            pptx_buffer = io.BytesIO()
            prs.save(pptx_buffer)
            pptx_buffer.seek(0)
            
            st.success("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ Ø¨Ù†Ø¬Ø§Ø­!")
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠ",
                data=pptx_buffer,
                file_name=f"student_statistics_{'_'.join(selected_classes_ppt)}.pptx",
                mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
            )
